{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70be26b2-d7ea-4ba5-800a-2c9136e1552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19d6b73-a499-4423-a916-5c7a99e9a7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4025a9-d08c-4929-ad03-fa6dc76f3441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(len(i) for i in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f18c241b-d75c-4403-83dd-fa521c5f14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E k w\n",
      "m a o\n",
      "m m m\n",
      "a m m\n"
     ]
    }
   ],
   "source": [
    "for i,j,k in zip('Emma','kamma','wommo'):\n",
    "    print(i,j,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "135fcdb7-a7fe-4160-8fe3-65ac78b6faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "b={}\n",
    "for i in words:\n",
    "    chs = ['<S>'] + list(i) +['<E>']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        bigram = (ch1,ch2)\n",
    "        b[bigram] = b.get(bigram,0)+1 #b[bigram]=0, if new bigram\n",
    "        #print(ch1,ch2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ede39ff-a803-402a-a10e-35f8d24a7705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('n', '<E>'), 6763),\n",
       " (('a', '<E>'), 6640),\n",
       " (('a', 'n'), 5438),\n",
       " (('<S>', 'a'), 4410),\n",
       " (('e', '<E>'), 3983),\n",
       " (('a', 'r'), 3264),\n",
       " (('e', 'l'), 3248),\n",
       " (('r', 'i'), 3033),\n",
       " (('n', 'a'), 2977),\n",
       " (('<S>', 'k'), 2963),\n",
       " (('l', 'e'), 2921),\n",
       " (('e', 'n'), 2675),\n",
       " (('l', 'a'), 2623),\n",
       " (('m', 'a'), 2590),\n",
       " (('<S>', 'm'), 2538),\n",
       " (('a', 'l'), 2528),\n",
       " (('i', '<E>'), 2489),\n",
       " (('l', 'i'), 2480),\n",
       " (('i', 'a'), 2445),\n",
       " (('<S>', 'j'), 2422),\n",
       " (('o', 'n'), 2411),\n",
       " (('h', '<E>'), 2409),\n",
       " (('r', 'a'), 2356),\n",
       " (('a', 'h'), 2332),\n",
       " (('h', 'a'), 2244),\n",
       " (('y', 'a'), 2143),\n",
       " (('i', 'n'), 2126),\n",
       " (('<S>', 's'), 2055),\n",
       " (('a', 'y'), 2050),\n",
       " (('y', '<E>'), 2007),\n",
       " (('e', 'r'), 1958),\n",
       " (('n', 'n'), 1906),\n",
       " (('y', 'n'), 1826),\n",
       " (('k', 'a'), 1731),\n",
       " (('n', 'i'), 1725),\n",
       " (('r', 'e'), 1697),\n",
       " (('<S>', 'd'), 1690),\n",
       " (('i', 'e'), 1653),\n",
       " (('a', 'i'), 1650),\n",
       " (('<S>', 'r'), 1639),\n",
       " (('a', 'm'), 1634),\n",
       " (('l', 'y'), 1588),\n",
       " (('<S>', 'l'), 1572),\n",
       " (('<S>', 'c'), 1542),\n",
       " (('<S>', 'e'), 1531),\n",
       " (('j', 'a'), 1473),\n",
       " (('r', '<E>'), 1377),\n",
       " (('n', 'e'), 1359),\n",
       " (('l', 'l'), 1345),\n",
       " (('i', 'l'), 1345),\n",
       " (('i', 's'), 1316),\n",
       " (('l', '<E>'), 1314),\n",
       " (('<S>', 't'), 1308),\n",
       " (('<S>', 'b'), 1306),\n",
       " (('d', 'a'), 1303),\n",
       " (('s', 'h'), 1285),\n",
       " (('d', 'e'), 1283),\n",
       " (('e', 'e'), 1271),\n",
       " (('m', 'i'), 1256),\n",
       " (('s', 'a'), 1201),\n",
       " (('s', '<E>'), 1169),\n",
       " (('<S>', 'n'), 1146),\n",
       " (('a', 's'), 1118),\n",
       " (('y', 'l'), 1104),\n",
       " (('e', 'y'), 1070),\n",
       " (('o', 'r'), 1059),\n",
       " (('a', 'd'), 1042),\n",
       " (('t', 'a'), 1027),\n",
       " (('<S>', 'z'), 929),\n",
       " (('v', 'i'), 911),\n",
       " (('k', 'e'), 895),\n",
       " (('s', 'e'), 884),\n",
       " (('<S>', 'h'), 874),\n",
       " (('r', 'o'), 869),\n",
       " (('e', 's'), 861),\n",
       " (('z', 'a'), 860),\n",
       " (('o', '<E>'), 855),\n",
       " (('i', 'r'), 849),\n",
       " (('b', 'r'), 842),\n",
       " (('a', 'v'), 834),\n",
       " (('m', 'e'), 818),\n",
       " (('e', 'i'), 818),\n",
       " (('c', 'a'), 815),\n",
       " (('i', 'y'), 779),\n",
       " (('r', 'y'), 773),\n",
       " (('e', 'm'), 769),\n",
       " (('s', 't'), 765),\n",
       " (('h', 'i'), 729),\n",
       " (('t', 'e'), 716),\n",
       " (('n', 'd'), 704),\n",
       " (('l', 'o'), 692),\n",
       " (('a', 'e'), 692),\n",
       " (('a', 't'), 687),\n",
       " (('s', 'i'), 684),\n",
       " (('e', 'a'), 679),\n",
       " (('d', 'i'), 674),\n",
       " (('h', 'e'), 674),\n",
       " (('<S>', 'g'), 669),\n",
       " (('t', 'o'), 667),\n",
       " (('c', 'h'), 664),\n",
       " (('b', 'e'), 655),\n",
       " (('t', 'h'), 647),\n",
       " (('v', 'a'), 642),\n",
       " (('o', 'l'), 619),\n",
       " (('<S>', 'i'), 591),\n",
       " (('i', 'o'), 588),\n",
       " (('e', 't'), 580),\n",
       " (('v', 'e'), 568),\n",
       " (('a', 'k'), 568),\n",
       " (('a', 'a'), 556),\n",
       " (('c', 'e'), 551),\n",
       " (('a', 'b'), 541),\n",
       " (('i', 't'), 541),\n",
       " (('<S>', 'y'), 535),\n",
       " (('t', 'i'), 532),\n",
       " (('s', 'o'), 531),\n",
       " (('m', '<E>'), 516),\n",
       " (('d', '<E>'), 516),\n",
       " (('<S>', 'p'), 515),\n",
       " (('i', 'c'), 509),\n",
       " (('k', 'i'), 509),\n",
       " (('o', 's'), 504),\n",
       " (('n', 'o'), 496),\n",
       " (('t', '<E>'), 483),\n",
       " (('j', 'o'), 479),\n",
       " (('u', 's'), 474),\n",
       " (('a', 'c'), 470),\n",
       " (('n', 'y'), 465),\n",
       " (('e', 'v'), 463),\n",
       " (('s', 's'), 461),\n",
       " (('m', 'o'), 452),\n",
       " (('i', 'k'), 445),\n",
       " (('n', 't'), 443),\n",
       " (('i', 'd'), 440),\n",
       " (('j', 'e'), 440),\n",
       " (('a', 'z'), 435),\n",
       " (('i', 'g'), 428),\n",
       " (('i', 'm'), 427),\n",
       " (('r', 'r'), 425),\n",
       " (('d', 'r'), 424),\n",
       " (('<S>', 'f'), 417),\n",
       " (('u', 'r'), 414),\n",
       " (('r', 'l'), 413),\n",
       " (('y', 's'), 401),\n",
       " (('<S>', 'o'), 394),\n",
       " (('e', 'd'), 384),\n",
       " (('a', 'u'), 381),\n",
       " (('c', 'o'), 380),\n",
       " (('k', 'y'), 379),\n",
       " (('d', 'o'), 378),\n",
       " (('<S>', 'v'), 376),\n",
       " (('t', 't'), 374),\n",
       " (('z', 'e'), 373),\n",
       " (('z', 'i'), 364),\n",
       " (('k', '<E>'), 363),\n",
       " (('g', 'h'), 360),\n",
       " (('t', 'r'), 352),\n",
       " (('k', 'o'), 344),\n",
       " (('t', 'y'), 341),\n",
       " (('g', 'e'), 334),\n",
       " (('g', 'a'), 330),\n",
       " (('l', 'u'), 324),\n",
       " (('b', 'a'), 321),\n",
       " (('d', 'y'), 317),\n",
       " (('c', 'k'), 316),\n",
       " (('<S>', 'w'), 307),\n",
       " (('k', 'h'), 307),\n",
       " (('u', 'l'), 301),\n",
       " (('y', 'e'), 301),\n",
       " (('y', 'r'), 291),\n",
       " (('m', 'y'), 287),\n",
       " (('h', 'o'), 287),\n",
       " (('w', 'a'), 280),\n",
       " (('s', 'l'), 279),\n",
       " (('n', 's'), 278),\n",
       " (('i', 'z'), 277),\n",
       " (('u', 'n'), 275),\n",
       " (('o', 'u'), 275),\n",
       " (('n', 'g'), 273),\n",
       " (('y', 'd'), 272),\n",
       " (('c', 'i'), 271),\n",
       " (('y', 'o'), 271),\n",
       " (('i', 'v'), 269),\n",
       " (('e', 'o'), 269),\n",
       " (('o', 'm'), 261),\n",
       " (('r', 'u'), 252),\n",
       " (('f', 'a'), 242),\n",
       " (('b', 'i'), 217),\n",
       " (('s', 'y'), 215),\n",
       " (('n', 'c'), 213),\n",
       " (('h', 'y'), 213),\n",
       " (('p', 'a'), 209),\n",
       " (('r', 't'), 208),\n",
       " (('q', 'u'), 206),\n",
       " (('p', 'h'), 204),\n",
       " (('h', 'r'), 204),\n",
       " (('j', 'u'), 202),\n",
       " (('g', 'r'), 201),\n",
       " (('p', 'e'), 197),\n",
       " (('n', 'l'), 195),\n",
       " (('y', 'i'), 192),\n",
       " (('g', 'i'), 190),\n",
       " (('o', 'd'), 190),\n",
       " (('r', 's'), 190),\n",
       " (('r', 'd'), 187),\n",
       " (('h', 'l'), 185),\n",
       " (('s', 'u'), 185),\n",
       " (('a', 'x'), 182),\n",
       " (('e', 'z'), 181),\n",
       " (('e', 'k'), 178),\n",
       " (('o', 'v'), 176),\n",
       " (('a', 'j'), 175),\n",
       " (('o', 'h'), 171),\n",
       " (('u', 'e'), 169),\n",
       " (('m', 'm'), 168),\n",
       " (('a', 'g'), 168),\n",
       " (('h', 'u'), 166),\n",
       " (('x', '<E>'), 164),\n",
       " (('u', 'a'), 163),\n",
       " (('r', 'm'), 162),\n",
       " (('a', 'w'), 161),\n",
       " (('f', 'i'), 160),\n",
       " (('z', '<E>'), 160),\n",
       " (('u', '<E>'), 155),\n",
       " (('u', 'm'), 154),\n",
       " (('e', 'c'), 153),\n",
       " (('v', 'o'), 153),\n",
       " (('e', 'h'), 152),\n",
       " (('p', 'r'), 151),\n",
       " (('d', 'd'), 149),\n",
       " (('o', 'a'), 149),\n",
       " (('w', 'e'), 149),\n",
       " (('w', 'i'), 148),\n",
       " (('y', 'm'), 148),\n",
       " (('z', 'y'), 147),\n",
       " (('n', 'z'), 145),\n",
       " (('y', 'u'), 141),\n",
       " (('r', 'n'), 140),\n",
       " (('o', 'b'), 140),\n",
       " (('k', 'l'), 139),\n",
       " (('m', 'u'), 139),\n",
       " (('l', 'd'), 138),\n",
       " (('h', 'n'), 138),\n",
       " (('u', 'd'), 136),\n",
       " (('<S>', 'x'), 134),\n",
       " (('t', 'l'), 134),\n",
       " (('a', 'f'), 134),\n",
       " (('o', 'e'), 132),\n",
       " (('e', 'x'), 132),\n",
       " (('e', 'g'), 125),\n",
       " (('f', 'e'), 123),\n",
       " (('z', 'l'), 123),\n",
       " (('u', 'i'), 121),\n",
       " (('v', 'y'), 121),\n",
       " (('e', 'b'), 121),\n",
       " (('r', 'h'), 121),\n",
       " (('j', 'i'), 119),\n",
       " (('o', 't'), 118),\n",
       " (('d', 'h'), 118),\n",
       " (('h', 'm'), 117),\n",
       " (('c', 'l'), 116),\n",
       " (('o', 'o'), 115),\n",
       " (('y', 'c'), 115),\n",
       " (('o', 'w'), 114),\n",
       " (('o', 'c'), 114),\n",
       " (('f', 'r'), 114),\n",
       " (('b', '<E>'), 114),\n",
       " (('m', 'b'), 112),\n",
       " (('z', 'o'), 110),\n",
       " (('i', 'b'), 110),\n",
       " (('i', 'u'), 109),\n",
       " (('k', 'r'), 109),\n",
       " (('g', '<E>'), 108),\n",
       " (('y', 'v'), 106),\n",
       " (('t', 'z'), 105),\n",
       " (('b', 'o'), 105),\n",
       " (('c', 'y'), 104),\n",
       " (('y', 't'), 104),\n",
       " (('u', 'b'), 103),\n",
       " (('u', 'c'), 103),\n",
       " (('x', 'a'), 103),\n",
       " (('b', 'l'), 103),\n",
       " (('o', 'y'), 103),\n",
       " (('x', 'i'), 102),\n",
       " (('i', 'f'), 101),\n",
       " (('r', 'c'), 99),\n",
       " (('c', '<E>'), 97),\n",
       " (('m', 'r'), 97),\n",
       " (('n', 'u'), 96),\n",
       " (('o', 'p'), 95),\n",
       " (('i', 'h'), 95),\n",
       " (('k', 's'), 95),\n",
       " (('l', 's'), 94),\n",
       " (('u', 'k'), 93),\n",
       " (('<S>', 'q'), 92),\n",
       " (('d', 'u'), 92),\n",
       " (('s', 'm'), 90),\n",
       " (('r', 'k'), 90),\n",
       " (('i', 'x'), 89),\n",
       " (('v', '<E>'), 88),\n",
       " (('y', 'k'), 86),\n",
       " (('u', 'w'), 86),\n",
       " (('g', 'u'), 85),\n",
       " (('b', 'y'), 83),\n",
       " (('e', 'p'), 83),\n",
       " (('g', 'o'), 83),\n",
       " (('s', 'k'), 82),\n",
       " (('u', 't'), 82),\n",
       " (('a', 'p'), 82),\n",
       " (('e', 'f'), 82),\n",
       " (('i', 'i'), 82),\n",
       " (('r', 'v'), 80),\n",
       " (('f', '<E>'), 80),\n",
       " (('t', 'u'), 78),\n",
       " (('y', 'z'), 78),\n",
       " (('<S>', 'u'), 78),\n",
       " (('l', 't'), 77),\n",
       " (('r', 'g'), 76),\n",
       " (('c', 'r'), 76),\n",
       " (('i', 'j'), 76),\n",
       " (('w', 'y'), 73),\n",
       " (('z', 'u'), 73),\n",
       " (('l', 'v'), 72),\n",
       " (('h', 't'), 71),\n",
       " (('j', '<E>'), 71),\n",
       " (('x', 't'), 70),\n",
       " (('o', 'i'), 69),\n",
       " (('e', 'u'), 69),\n",
       " (('o', 'k'), 68),\n",
       " (('b', 'd'), 65),\n",
       " (('a', 'o'), 63),\n",
       " (('p', 'i'), 61),\n",
       " (('s', 'c'), 60),\n",
       " (('d', 'l'), 60),\n",
       " (('l', 'm'), 60),\n",
       " (('a', 'q'), 60),\n",
       " (('f', 'o'), 60),\n",
       " (('p', 'o'), 59),\n",
       " (('n', 'k'), 58),\n",
       " (('w', 'n'), 58),\n",
       " (('u', 'h'), 58),\n",
       " (('e', 'j'), 55),\n",
       " (('n', 'v'), 55),\n",
       " (('s', 'r'), 55),\n",
       " (('o', 'z'), 54),\n",
       " (('i', 'p'), 53),\n",
       " (('l', 'b'), 52),\n",
       " (('i', 'q'), 52),\n",
       " (('w', '<E>'), 51),\n",
       " (('m', 'c'), 51),\n",
       " (('s', 'p'), 51),\n",
       " (('e', 'w'), 50),\n",
       " (('k', 'u'), 50),\n",
       " (('v', 'r'), 48),\n",
       " (('u', 'g'), 47),\n",
       " (('o', 'x'), 45),\n",
       " (('u', 'z'), 45),\n",
       " (('z', 'z'), 45),\n",
       " (('j', 'h'), 45),\n",
       " (('b', 'u'), 45),\n",
       " (('o', 'g'), 44),\n",
       " (('n', 'r'), 44),\n",
       " (('f', 'f'), 44),\n",
       " (('n', 'j'), 44),\n",
       " (('z', 'h'), 43),\n",
       " (('c', 'c'), 42),\n",
       " (('r', 'b'), 41),\n",
       " (('x', 'o'), 41),\n",
       " (('b', 'h'), 41),\n",
       " (('p', 'p'), 39),\n",
       " (('x', 'l'), 39),\n",
       " (('h', 'v'), 39),\n",
       " (('b', 'b'), 38),\n",
       " (('m', 'p'), 38),\n",
       " (('x', 'x'), 38),\n",
       " (('u', 'v'), 37),\n",
       " (('x', 'e'), 36),\n",
       " (('w', 'o'), 36),\n",
       " (('c', 't'), 35),\n",
       " (('z', 'm'), 35),\n",
       " (('t', 's'), 35),\n",
       " (('m', 's'), 35),\n",
       " (('c', 'u'), 35),\n",
       " (('o', 'f'), 34),\n",
       " (('u', 'x'), 34),\n",
       " (('k', 'w'), 34),\n",
       " (('p', '<E>'), 33),\n",
       " (('g', 'l'), 32),\n",
       " (('z', 'r'), 32),\n",
       " (('d', 'n'), 31),\n",
       " (('g', 't'), 31),\n",
       " (('g', 'y'), 31),\n",
       " (('h', 's'), 31),\n",
       " (('x', 's'), 31),\n",
       " (('g', 's'), 30),\n",
       " (('x', 'y'), 30),\n",
       " (('y', 'g'), 30),\n",
       " (('d', 'm'), 30),\n",
       " (('d', 's'), 29),\n",
       " (('h', 'k'), 29),\n",
       " (('y', 'x'), 28),\n",
       " (('q', '<E>'), 28),\n",
       " (('g', 'n'), 27),\n",
       " (('y', 'b'), 27),\n",
       " (('g', 'w'), 26),\n",
       " (('n', 'h'), 26),\n",
       " (('k', 'n'), 26),\n",
       " (('g', 'g'), 25),\n",
       " (('d', 'g'), 25),\n",
       " (('l', 'c'), 25),\n",
       " (('r', 'j'), 25),\n",
       " (('w', 'u'), 25),\n",
       " (('l', 'k'), 24),\n",
       " (('m', 'd'), 24),\n",
       " (('s', 'w'), 24),\n",
       " (('s', 'n'), 24),\n",
       " (('h', 'd'), 24),\n",
       " (('w', 'h'), 23),\n",
       " (('y', 'j'), 23),\n",
       " (('y', 'y'), 23),\n",
       " (('r', 'z'), 23),\n",
       " (('d', 'w'), 23),\n",
       " (('w', 'r'), 22),\n",
       " (('t', 'n'), 22),\n",
       " (('l', 'f'), 22),\n",
       " (('y', 'h'), 22),\n",
       " (('r', 'w'), 21),\n",
       " (('s', 'b'), 21),\n",
       " (('m', 'n'), 20),\n",
       " (('f', 'l'), 20),\n",
       " (('w', 's'), 20),\n",
       " (('k', 'k'), 20),\n",
       " (('h', 'z'), 20),\n",
       " (('g', 'd'), 19),\n",
       " (('l', 'h'), 19),\n",
       " (('n', 'm'), 19),\n",
       " (('x', 'z'), 19),\n",
       " (('u', 'f'), 19),\n",
       " (('f', 't'), 18),\n",
       " (('l', 'r'), 18),\n",
       " (('p', 't'), 17),\n",
       " (('t', 'c'), 17),\n",
       " (('k', 't'), 17),\n",
       " (('d', 'v'), 17),\n",
       " (('u', 'p'), 16),\n",
       " (('p', 'l'), 16),\n",
       " (('l', 'w'), 16),\n",
       " (('p', 's'), 16),\n",
       " (('o', 'j'), 16),\n",
       " (('r', 'q'), 16),\n",
       " (('y', 'p'), 15),\n",
       " (('l', 'p'), 15),\n",
       " (('t', 'v'), 15),\n",
       " (('r', 'p'), 14),\n",
       " (('l', 'n'), 14),\n",
       " (('e', 'q'), 14),\n",
       " (('f', 'y'), 14),\n",
       " (('s', 'v'), 14),\n",
       " (('u', 'j'), 14),\n",
       " (('v', 'l'), 14),\n",
       " (('q', 'a'), 13),\n",
       " (('u', 'y'), 13),\n",
       " (('q', 'i'), 13),\n",
       " (('w', 'l'), 13),\n",
       " (('p', 'y'), 12),\n",
       " (('y', 'f'), 12),\n",
       " (('c', 'q'), 11),\n",
       " (('j', 'r'), 11),\n",
       " (('n', 'w'), 11),\n",
       " (('n', 'f'), 11),\n",
       " (('t', 'w'), 11),\n",
       " (('m', 'z'), 11),\n",
       " (('u', 'o'), 10),\n",
       " (('f', 'u'), 10),\n",
       " (('l', 'z'), 10),\n",
       " (('h', 'w'), 10),\n",
       " (('u', 'q'), 10),\n",
       " (('j', 'y'), 10),\n",
       " (('s', 'z'), 10),\n",
       " (('s', 'd'), 9),\n",
       " (('j', 'l'), 9),\n",
       " (('d', 'j'), 9),\n",
       " (('k', 'm'), 9),\n",
       " (('r', 'f'), 9),\n",
       " (('h', 'j'), 9),\n",
       " (('v', 'n'), 8),\n",
       " (('n', 'b'), 8),\n",
       " (('i', 'w'), 8),\n",
       " (('h', 'b'), 8),\n",
       " (('b', 's'), 8),\n",
       " (('w', 't'), 8),\n",
       " (('w', 'd'), 8),\n",
       " (('v', 'v'), 7),\n",
       " (('v', 'u'), 7),\n",
       " (('j', 's'), 7),\n",
       " (('m', 'j'), 7),\n",
       " (('f', 's'), 6),\n",
       " (('l', 'g'), 6),\n",
       " (('l', 'j'), 6),\n",
       " (('j', 'w'), 6),\n",
       " (('n', 'x'), 6),\n",
       " (('y', 'q'), 6),\n",
       " (('w', 'k'), 6),\n",
       " (('g', 'm'), 6),\n",
       " (('x', 'u'), 5),\n",
       " (('m', 'h'), 5),\n",
       " (('m', 'l'), 5),\n",
       " (('j', 'm'), 5),\n",
       " (('c', 's'), 5),\n",
       " (('j', 'v'), 5),\n",
       " (('n', 'p'), 5),\n",
       " (('d', 'f'), 5),\n",
       " (('x', 'd'), 5),\n",
       " (('z', 'b'), 4),\n",
       " (('f', 'n'), 4),\n",
       " (('x', 'c'), 4),\n",
       " (('m', 't'), 4),\n",
       " (('t', 'm'), 4),\n",
       " (('z', 'n'), 4),\n",
       " (('z', 't'), 4),\n",
       " (('p', 'u'), 4),\n",
       " (('c', 'z'), 4),\n",
       " (('b', 'n'), 4),\n",
       " (('z', 's'), 4),\n",
       " (('f', 'w'), 4),\n",
       " (('d', 't'), 4),\n",
       " (('j', 'd'), 4),\n",
       " (('j', 'c'), 4),\n",
       " (('y', 'w'), 4),\n",
       " (('v', 'k'), 3),\n",
       " (('x', 'w'), 3),\n",
       " (('t', 'j'), 3),\n",
       " (('c', 'j'), 3),\n",
       " (('q', 'w'), 3),\n",
       " (('g', 'b'), 3),\n",
       " (('o', 'q'), 3),\n",
       " (('r', 'x'), 3),\n",
       " (('d', 'c'), 3),\n",
       " (('g', 'j'), 3),\n",
       " (('x', 'f'), 3),\n",
       " (('z', 'w'), 3),\n",
       " (('d', 'k'), 3),\n",
       " (('u', 'u'), 3),\n",
       " (('m', 'v'), 3),\n",
       " (('c', 'x'), 3),\n",
       " (('l', 'q'), 3),\n",
       " (('p', 'b'), 2),\n",
       " (('t', 'g'), 2),\n",
       " (('q', 's'), 2),\n",
       " (('t', 'x'), 2),\n",
       " (('f', 'k'), 2),\n",
       " (('b', 't'), 2),\n",
       " (('j', 'n'), 2),\n",
       " (('k', 'c'), 2),\n",
       " (('z', 'k'), 2),\n",
       " (('s', 'j'), 2),\n",
       " (('s', 'f'), 2),\n",
       " (('z', 'j'), 2),\n",
       " (('n', 'q'), 2),\n",
       " (('f', 'z'), 2),\n",
       " (('h', 'g'), 2),\n",
       " (('w', 'w'), 2),\n",
       " (('k', 'j'), 2),\n",
       " (('j', 'k'), 2),\n",
       " (('w', 'm'), 2),\n",
       " (('z', 'c'), 2),\n",
       " (('z', 'v'), 2),\n",
       " (('w', 'f'), 2),\n",
       " (('q', 'm'), 2),\n",
       " (('k', 'z'), 2),\n",
       " (('j', 'j'), 2),\n",
       " (('z', 'p'), 2),\n",
       " (('j', 't'), 2),\n",
       " (('k', 'b'), 2),\n",
       " (('m', 'w'), 2),\n",
       " (('h', 'f'), 2),\n",
       " (('c', 'g'), 2),\n",
       " (('t', 'f'), 2),\n",
       " (('h', 'c'), 2),\n",
       " (('q', 'o'), 2),\n",
       " (('k', 'd'), 2),\n",
       " (('k', 'v'), 2),\n",
       " (('s', 'g'), 2),\n",
       " (('z', 'd'), 2),\n",
       " (('q', 'r'), 1),\n",
       " (('d', 'z'), 1),\n",
       " (('p', 'j'), 1),\n",
       " (('q', 'l'), 1),\n",
       " (('p', 'f'), 1),\n",
       " (('q', 'e'), 1),\n",
       " (('b', 'c'), 1),\n",
       " (('c', 'd'), 1),\n",
       " (('m', 'f'), 1),\n",
       " (('p', 'n'), 1),\n",
       " (('w', 'b'), 1),\n",
       " (('p', 'c'), 1),\n",
       " (('h', 'p'), 1),\n",
       " (('f', 'h'), 1),\n",
       " (('b', 'j'), 1),\n",
       " (('f', 'g'), 1),\n",
       " (('z', 'g'), 1),\n",
       " (('c', 'p'), 1),\n",
       " (('p', 'k'), 1),\n",
       " (('p', 'm'), 1),\n",
       " (('x', 'n'), 1),\n",
       " (('s', 'q'), 1),\n",
       " (('k', 'f'), 1),\n",
       " (('m', 'k'), 1),\n",
       " (('x', 'h'), 1),\n",
       " (('g', 'f'), 1),\n",
       " (('v', 'b'), 1),\n",
       " (('j', 'p'), 1),\n",
       " (('g', 'z'), 1),\n",
       " (('v', 'd'), 1),\n",
       " (('d', 'b'), 1),\n",
       " (('v', 'h'), 1),\n",
       " (('h', 'h'), 1),\n",
       " (('g', 'v'), 1),\n",
       " (('d', 'q'), 1),\n",
       " (('x', 'b'), 1),\n",
       " (('w', 'z'), 1),\n",
       " (('h', 'q'), 1),\n",
       " (('j', 'b'), 1),\n",
       " (('x', 'm'), 1),\n",
       " (('w', 'g'), 1),\n",
       " (('t', 'b'), 1),\n",
       " (('z', 'x'), 1)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(b.items(), key =  lambda k: -k[1])#b:-b[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4748a80c-4f86-4dd4-8cb9-fd63ff351bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "162bde59-2746-4b25-945c-f2baec63766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6000538b-52be-4355-9378-cdb4e1ea49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((27,27), dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3d1e7e01-e4a2-484e-82f1-37f14d85bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "99ba6531-a7aa-46ff-bb45-a4afbba77e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi ={s:i for i,s in enumerate(chars)}\n",
    "# stoi['<S>']=26\n",
    "# stoi['<E>']=27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1949c297-dbc6-4bca-ae43-3516b36f956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi ={s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.']=0\n",
    "itos ={s:i for i,s in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4f1785f-e489-431e-afae-47fb07e23afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in words:\n",
    "    chs = ['.'] + list(i) +['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        i1=stoi[ch1]\n",
    "        i2=stoi[ch2]\n",
    "        N[i1,i2]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4e2c9-97c0-454c-a86b-412d52856615",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2c7d3581-e6e9-420a-9a8e-47655d9e259c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26,\n",
       " '.': 0}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ec0a977c-000e-470b-afcb-ec956ad2c52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(N, cmap='Blues')\n",
    "for i in range(27):\n",
    "    for j in range(27):\n",
    "        chstr = itos[i] + itos[j]\n",
    "        plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
    "        plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "082d0b09-81ba-4645-b0cb-6319fc9e80c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 4410, 1306, 1542, 1690, 1531,  417,  669,  874,  591, 2422, 2963,\n",
       "        1572, 2538, 1146,  394,  515,   92, 1639, 2055, 1308,   78,  376,  307,\n",
       "         134,  535,  929], dtype=torch.int32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fcb04795-cb13-4f2e-9b40-0d9ae4262a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "779ecde8-0da8-4144-b720-937200eefca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.1377, 0.0408, 0.0481, 0.0528, 0.0478, 0.0130, 0.0209, 0.0273,\n",
       "        0.0184, 0.0756, 0.0925, 0.0491, 0.0792, 0.0358, 0.0123, 0.0161, 0.0029,\n",
       "        0.0512, 0.0642, 0.0408, 0.0024, 0.0117, 0.0096, 0.0042, 0.0167, 0.0290])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0].float()\n",
    "p=p/p.sum()\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "54b8629e-6d4a-4c6d-aaf1-cd5588c8375c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a8a373fd-a626-4ef9-81cb-76bfdc14739d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g= torch.Generator().manual_seed(2144)\n",
    "i = torch.multinomial(p,num_samples=1, replacement=True, generator=g).item()\n",
    "itos[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f8d6a3da-6f51-4b30-b308-9174f9b8278f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.multinomial(p,num_samples=1, replacement=True, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f5b31f55-d823-4942-978a-04591ce49245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.\n",
      "daneureeen.\n",
      "h.\n",
      "n.\n",
      "avararawilya.\n",
      "via.\n",
      "tavamyna.\n",
      "za.\n",
      "eya.\n",
      "e.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(10):\n",
    "    i=0\n",
    "    out=[]\n",
    "    while True:\n",
    "        p=N[i].float()\n",
    "        p=p/p.sum()\n",
    "        i=torch.multinomial(p,num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[i])\n",
    "        if i==0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "06866391-e9dd-4d0d-9e3e-e9ec02187630",
   "metadata": {},
   "outputs": [],
   "source": [
    "P =N.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d34f1363-533a-4add-9b21-7cdb7eb0e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P=(N+1).float()#smoothing which ensure there are no 0 values\n",
    "P=P/P.sum(1,keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "9b2062c0-e2a1-4bba-9b1c-e17eaf5527e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing is called regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ca8b29b9-98ec-45c4-ba30-7d46316cfd9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b36b45ae-e911-4691-889e-e40ec33aea8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[228], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m P[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "P['e','e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "e86ac587-0f18-4a18-8c3e-4ea365360fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zzl.\n",
      "deee.\n",
      "br.\n",
      "pfa.\n",
      "mavan.\n",
      "oneele.\n",
      "khanlie.\n",
      "a.\n",
      "a.\n",
      "sa.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    i=0\n",
    "    out=[]\n",
    "    while True:\n",
    "        p=P[i]\n",
    "        i=torch.multinomial(p,num_samples=1, replacement=True, generator=g).item()\n",
    "        out.append(itos[i])\n",
    "        if i==0:\n",
    "            break\n",
    "    print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a17a7c0e-6e50-401f-87ba-b52fcd2ccf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037037037037037035"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "60ed6385-2869-480a-8991-4621e4d110cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". j tensor(0.0756) tensor(-2.5826)\n",
      "j w tensor(0.0024) tensor(-6.0358)\n",
      "w a tensor(0.2939) tensor(-1.2244)\n",
      "a l tensor(0.0746) tensor(-2.5959)\n",
      "l i tensor(0.1774) tensor(-1.7293)\n",
      "i t tensor(0.0306) tensor(-3.4876)\n",
      "t h tensor(0.1158) tensor(-2.1561)\n",
      "h . tensor(0.3153) tensor(-1.1542)\n",
      "tensor(2.6207)\n"
     ]
    }
   ],
   "source": [
    "log_lik=0.0\n",
    "n=0\n",
    "# for i in words:\n",
    "for i in [\"jwalith\"]:\n",
    "    chs = ['.'] + list(i) +['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        i1=stoi[ch1]\n",
    "        i2=stoi[ch2]\n",
    "        # print(i1,i2)\n",
    "        prob = P[i1,i2]\n",
    "        logprob=torch.log(prob) #scaling: we use log as to make values bigger as we are multiplyng the prob which are 0.23 or 0.004\n",
    "        log_lik+=logprob #likelihood is product of all individual prob but as we are doing log we add all \n",
    "        n+=1\n",
    "        nll=-log_lik # we make it -ve as to look good as usually log_lik give -ve values also in los function low is good i.e 0 is good but here 0 is bad\n",
    "        # print(log_lik,nll)\n",
    "        print(ch1,ch2,prob,logprob)\n",
    "loss=nll/n# normalize\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7365805-b2b5-4c63-a6d8-f684cd5eccbd",
   "metadata": {},
   "source": [
    "#### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6a759c89-dbc0-4b30-8b03-839fff880bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create bigram training set (x,y)\n",
    "xs,ys =[],[]\n",
    "for i in words[:2]:\n",
    "    chs = ['.'] + list(i) +['.']\n",
    "    for ch1,ch2 in zip(chs,chs[1:]):\n",
    "        i1=stoi[ch1]\n",
    "        i2=stoi[ch2]\n",
    "        xs.append(i1)\n",
    "        ys.append(i2)\n",
    "#print(xs,ys)\n",
    "xs=torch.tensor(xs)\n",
    "ys=torch.tensor(ys)\n",
    "# print(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7a8bfe09-c1fb-4667-a16d-b790d433ff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "65476c2b-3559-4238-8ea1-5fe930290eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc =F.one_hot(xs, num_classes=27).float() # we do one hot encoding as training with integers[categories] does not make sense so we vectorise\n",
    "xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dfc60c07-a7b4-4975-8b39-580a5dff6970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "af6aec44-4f01-4d7d-86c2-7c82c8fc4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "W= torch.randn((27,27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "084ae073-0d7a-420c-b94d-5efafce675f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1367e+00, -9.3284e-01,  1.4748e+00, -1.9887e+00, -1.2293e-01,\n",
       "         -7.3457e-01,  6.6342e-01,  5.8790e-01, -2.1922e-01, -1.4595e+00,\n",
       "         -5.4109e-01,  1.7948e+00, -5.6509e-01,  1.2757e-02,  8.4009e-01,\n",
       "         -7.4964e-01,  1.8919e-01, -2.8810e-02,  1.8103e+00,  1.7439e-01,\n",
       "          1.7887e+00, -3.3929e-01,  1.8233e+00,  5.4474e-01, -1.8864e+00,\n",
       "          1.4099e+00, -2.1383e+00],\n",
       "        [ 2.1188e+00,  7.4008e-01, -5.0044e-01, -9.6904e-01,  1.4595e-02,\n",
       "         -1.5905e-01, -1.1907e+00,  1.8111e+00, -1.8887e-01, -1.8649e+00,\n",
       "          4.9495e-01,  1.8772e+00, -3.3198e-01, -6.2372e-01,  1.0927e-01,\n",
       "          5.0246e-01, -3.7613e-01,  1.2864e+00,  8.0500e-01,  2.6918e+00,\n",
       "         -1.2163e+00, -1.9447e+00,  7.6837e-01,  3.3587e-01, -1.0391e+00,\n",
       "          7.0536e-01, -1.9241e-01],\n",
       "        [ 1.2708e+00,  7.2251e-01,  1.3517e+00, -6.6902e-02,  1.8329e+00,\n",
       "         -1.1122e+00, -3.9575e-01,  1.1188e+00, -1.2469e+00,  4.1258e-01,\n",
       "         -4.7521e-01,  3.3885e-01, -1.9999e+00,  1.6874e-01,  5.7904e-01,\n",
       "         -1.5774e+00, -1.0964e+00, -1.7613e+00,  4.4815e-01, -1.0162e+00,\n",
       "          2.0018e-01,  6.0642e-01,  1.7978e+00, -1.1951e+00, -2.2185e-01,\n",
       "          6.7042e-01,  6.9299e-01],\n",
       "        [ 1.2708e+00,  7.2251e-01,  1.3517e+00, -6.6902e-02,  1.8329e+00,\n",
       "         -1.1122e+00, -3.9575e-01,  1.1188e+00, -1.2469e+00,  4.1258e-01,\n",
       "         -4.7521e-01,  3.3885e-01, -1.9999e+00,  1.6874e-01,  5.7904e-01,\n",
       "         -1.5774e+00, -1.0964e+00, -1.7613e+00,  4.4815e-01, -1.0162e+00,\n",
       "          2.0018e-01,  6.0642e-01,  1.7978e+00, -1.1951e+00, -2.2185e-01,\n",
       "          6.7042e-01,  6.9299e-01],\n",
       "        [ 3.5014e-02, -7.7847e-01, -1.1645e+00, -1.0444e+00, -7.5906e-01,\n",
       "         -1.3810e-02, -4.4069e-01, -1.1086e+00,  1.7091e+00,  1.6217e+00,\n",
       "         -4.9044e-01, -7.1887e-01,  7.8840e-01, -1.3506e+00,  7.3561e-01,\n",
       "          5.3291e-01,  2.0150e+00,  8.7003e-01, -1.6868e+00, -6.8441e-01,\n",
       "         -4.3702e-03, -1.0478e+00,  7.0042e-01,  1.8968e+00,  5.6965e-01,\n",
       "          7.1147e-01, -1.7280e+00],\n",
       "        [-1.1367e+00, -9.3284e-01,  1.4748e+00, -1.9887e+00, -1.2293e-01,\n",
       "         -7.3457e-01,  6.6342e-01,  5.8790e-01, -2.1922e-01, -1.4595e+00,\n",
       "         -5.4109e-01,  1.7948e+00, -5.6509e-01,  1.2757e-02,  8.4009e-01,\n",
       "         -7.4964e-01,  1.8919e-01, -2.8810e-02,  1.8103e+00,  1.7439e-01,\n",
       "          1.7887e+00, -3.3929e-01,  1.8233e+00,  5.4474e-01, -1.8864e+00,\n",
       "          1.4099e+00, -2.1383e+00],\n",
       "        [-3.8508e-01,  7.1683e-01,  1.6240e+00,  2.0861e-02,  1.9318e-01,\n",
       "          2.8063e-01, -4.3676e-01, -2.8098e-01, -2.2430e-01,  2.9024e-01,\n",
       "         -1.8796e-01,  2.0053e-03,  1.6656e+00, -1.1724e+00, -8.7351e-01,\n",
       "          4.1487e-01,  8.1676e-01,  1.1762e+00, -7.3133e-01,  4.0543e-01,\n",
       "         -1.5445e+00,  2.9589e-01, -3.6368e-01,  7.3498e-01,  3.9633e-01,\n",
       "         -5.3410e-01, -6.0645e-01],\n",
       "        [-1.7769e+00,  1.4345e+00, -5.8074e-02,  5.1520e-01, -9.2976e-01,\n",
       "          1.0969e+00, -9.6510e-01,  6.2157e-01, -1.2057e+00,  4.6271e-01,\n",
       "         -3.1581e-01, -1.6650e+00, -5.1803e-01,  2.9489e-01,  9.0197e-01,\n",
       "          2.2342e-01, -2.8832e+00, -8.6462e-01,  4.0502e-01, -1.9127e+00,\n",
       "         -6.4990e-01, -4.1521e-02, -1.2406e+00,  1.0157e+00,  8.1561e-02,\n",
       "          1.3477e+00, -2.4648e-01],\n",
       "        [-9.2876e-01, -5.5066e-01,  2.7570e-01, -6.5629e-02, -2.2193e-01,\n",
       "         -2.8972e-01,  3.8652e-01, -2.0239e+00, -1.9708e+00,  4.6394e-01,\n",
       "          1.4617e+00, -6.4818e-02, -5.7243e-01,  1.1064e-01,  1.3757e+00,\n",
       "          2.1067e+00, -2.1796e-01, -3.8086e-01, -3.1821e-01, -3.9126e-01,\n",
       "         -2.4405e-01, -1.3236e-01,  5.6513e-01,  1.3383e-01, -1.4388e-01,\n",
       "         -2.6395e-02,  1.3080e+00],\n",
       "        [-1.5895e-01, -1.1067e+00,  2.8015e-01,  3.8415e-01, -5.1108e-01,\n",
       "          2.2617e+00,  5.9120e-01, -1.6709e+00, -6.1670e-01,  5.5517e-01,\n",
       "          3.0901e-01,  8.2679e-01,  6.4106e-02, -1.1186e+00,  7.6541e-01,\n",
       "          3.1275e-01, -7.6168e-01, -6.2065e-01, -3.1567e-01, -4.1999e-01,\n",
       "          7.3489e-01, -9.5219e-01, -3.7036e-02, -5.6928e-01,  1.9854e+00,\n",
       "          1.1416e+00,  1.7412e+00],\n",
       "        [-9.2876e-01, -5.5066e-01,  2.7570e-01, -6.5629e-02, -2.2193e-01,\n",
       "         -2.8972e-01,  3.8652e-01, -2.0239e+00, -1.9708e+00,  4.6394e-01,\n",
       "          1.4617e+00, -6.4818e-02, -5.7243e-01,  1.1064e-01,  1.3757e+00,\n",
       "          2.1067e+00, -2.1796e-01, -3.8086e-01, -3.1821e-01, -3.9126e-01,\n",
       "         -2.4405e-01, -1.3236e-01,  5.6513e-01,  1.3383e-01, -1.4388e-01,\n",
       "         -2.6395e-02,  1.3080e+00],\n",
       "        [ 3.5014e-02, -7.7847e-01, -1.1645e+00, -1.0444e+00, -7.5906e-01,\n",
       "         -1.3810e-02, -4.4069e-01, -1.1086e+00,  1.7091e+00,  1.6217e+00,\n",
       "         -4.9044e-01, -7.1887e-01,  7.8840e-01, -1.3506e+00,  7.3561e-01,\n",
       "          5.3291e-01,  2.0150e+00,  8.7003e-01, -1.6868e+00, -6.8441e-01,\n",
       "         -4.3702e-03, -1.0478e+00,  7.0042e-01,  1.8968e+00,  5.6965e-01,\n",
       "          7.1147e-01, -1.7280e+00]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc @ W # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3e75de1c-60d9-44c5-840e-dbe2a0bfd86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0063, 0.0077, 0.0860, 0.0027, 0.0174, 0.0094, 0.0382, 0.0354, 0.0158,\n",
       "         0.0046, 0.0115, 0.1185, 0.0112, 0.0199, 0.0456, 0.0093, 0.0238, 0.0191,\n",
       "         0.1203, 0.0234, 0.1178, 0.0140, 0.1219, 0.0339, 0.0030, 0.0806, 0.0023],\n",
       "        [0.1356, 0.0342, 0.0099, 0.0062, 0.0165, 0.0139, 0.0050, 0.0997, 0.0135,\n",
       "         0.0025, 0.0267, 0.1065, 0.0117, 0.0087, 0.0182, 0.0269, 0.0112, 0.0590,\n",
       "         0.0364, 0.2405, 0.0048, 0.0023, 0.0351, 0.0228, 0.0058, 0.0330, 0.0134],\n",
       "        [0.0802, 0.0463, 0.0869, 0.0210, 0.1406, 0.0074, 0.0151, 0.0689, 0.0065,\n",
       "         0.0340, 0.0140, 0.0316, 0.0030, 0.0266, 0.0401, 0.0046, 0.0075, 0.0039,\n",
       "         0.0352, 0.0081, 0.0275, 0.0413, 0.1358, 0.0068, 0.0180, 0.0440, 0.0450],\n",
       "        [0.0802, 0.0463, 0.0869, 0.0210, 0.1406, 0.0074, 0.0151, 0.0689, 0.0065,\n",
       "         0.0340, 0.0140, 0.0316, 0.0030, 0.0266, 0.0401, 0.0046, 0.0075, 0.0039,\n",
       "         0.0352, 0.0081, 0.0275, 0.0413, 0.1358, 0.0068, 0.0180, 0.0440, 0.0450],\n",
       "        [0.0220, 0.0097, 0.0066, 0.0075, 0.0099, 0.0209, 0.0137, 0.0070, 0.1173,\n",
       "         0.1075, 0.0130, 0.0103, 0.0467, 0.0055, 0.0443, 0.0362, 0.1592, 0.0507,\n",
       "         0.0039, 0.0107, 0.0211, 0.0074, 0.0428, 0.1415, 0.0375, 0.0432, 0.0038],\n",
       "        [0.0063, 0.0077, 0.0860, 0.0027, 0.0174, 0.0094, 0.0382, 0.0354, 0.0158,\n",
       "         0.0046, 0.0115, 0.1185, 0.0112, 0.0199, 0.0456, 0.0093, 0.0238, 0.0191,\n",
       "         0.1203, 0.0234, 0.1178, 0.0140, 0.1219, 0.0339, 0.0030, 0.0806, 0.0023],\n",
       "        [0.0176, 0.0529, 0.1311, 0.0264, 0.0313, 0.0342, 0.0167, 0.0195, 0.0206,\n",
       "         0.0345, 0.0214, 0.0259, 0.1367, 0.0080, 0.0108, 0.0391, 0.0585, 0.0838,\n",
       "         0.0124, 0.0388, 0.0055, 0.0347, 0.0180, 0.0539, 0.0384, 0.0151, 0.0141],\n",
       "        [0.0051, 0.1255, 0.0282, 0.0500, 0.0118, 0.0895, 0.0114, 0.0557, 0.0090,\n",
       "         0.0475, 0.0218, 0.0057, 0.0178, 0.0402, 0.0737, 0.0374, 0.0017, 0.0126,\n",
       "         0.0448, 0.0044, 0.0156, 0.0287, 0.0086, 0.0826, 0.0324, 0.1151, 0.0234],\n",
       "        [0.0098, 0.0143, 0.0328, 0.0233, 0.0199, 0.0186, 0.0366, 0.0033, 0.0035,\n",
       "         0.0395, 0.1073, 0.0233, 0.0140, 0.0278, 0.0984, 0.2044, 0.0200, 0.0170,\n",
       "         0.0181, 0.0168, 0.0195, 0.0218, 0.0438, 0.0284, 0.0215, 0.0242, 0.0920],\n",
       "        [0.0172, 0.0067, 0.0267, 0.0297, 0.0121, 0.1939, 0.0365, 0.0038, 0.0109,\n",
       "         0.0352, 0.0275, 0.0462, 0.0215, 0.0066, 0.0434, 0.0276, 0.0094, 0.0109,\n",
       "         0.0147, 0.0133, 0.0421, 0.0078, 0.0195, 0.0114, 0.1471, 0.0632, 0.1152],\n",
       "        [0.0098, 0.0143, 0.0328, 0.0233, 0.0199, 0.0186, 0.0366, 0.0033, 0.0035,\n",
       "         0.0395, 0.1073, 0.0233, 0.0140, 0.0278, 0.0984, 0.2044, 0.0200, 0.0170,\n",
       "         0.0181, 0.0168, 0.0195, 0.0218, 0.0438, 0.0284, 0.0215, 0.0242, 0.0920],\n",
       "        [0.0220, 0.0097, 0.0066, 0.0075, 0.0099, 0.0209, 0.0137, 0.0070, 0.1173,\n",
       "         0.1075, 0.0130, 0.0103, 0.0467, 0.0055, 0.0443, 0.0362, 0.1592, 0.0507,\n",
       "         0.0039, 0.0107, 0.0211, 0.0074, 0.0428, 0.1415, 0.0375, 0.0432, 0.0038]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are differentable operations(+,*,exp()). the output of wx(NN) we will transfrom into probabilities\n",
    "logits = xenc @ W # interpretting as log-counts\n",
    "counts = logits.exp() # equivalent N, here we are applying exp function to have values if -ve then exp value will be between 0-1 if +ve then exp value will be more than 1\n",
    "probs = counts / counts.sum(1, keepdims=True) # sum of the probs =1\n",
    "probs\n",
    "#last 2 lines called softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "30336189-42ae-4927-8ee0-2a91b3cd1549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "8d41d9cb-da6c-48d8-83e5-99d6caa1dae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1])"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "dd6b3f26-38a4-4f96-bbee-998ffcacd4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7b0684aa-0e8f-4a54-80eb-8cf6f310af21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0094), tensor(0.0087), tensor(0.0266))"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[0,5], probs[1,13], probs[2,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e1a37aa8-f347-41a1-bca9-2efb59bd9f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "128af619-1648-4923-bd5e-e106725f0d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "cadd7684-5cd2-45e4-84cc-4f0c348a68b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0094, 0.0087, 0.0266, 0.0463, 0.0220, 0.0093, 0.1367, 0.0475, 0.0438,\n",
       "        0.0352, 0.0143, 0.0220])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vector loss\n",
    "probs[torch.arange(12), ys]\n",
    "#these are probabilities we are interested in i,e in the output these values should have higher probalities.i.e for the first letter after 0, 5 should come with more prob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "dbeb678e-87df-4c0b-91ad-135fd9dab392",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -probs[torch.arange(12), ys].log().mean() # -ve likely hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1dcc63ce-b971-4abd-a20d-3a8715973b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6809)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ba9a5bbc-abfd-4494-9834-9a1771307f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "9fce45d2-1996-4277-97fd-12e58060ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "logits = xenc @ W # predict log-counts\n",
    "counts = logits.exp() # counts, equivalent to N\n",
    "probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "loss = -probs[torch.arange(12), ys].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c6178eb6-3c48-4a2c-9215-50cb4855b92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2762, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "243d59e2-fc1b-4af2-93f3-ed2b41ce92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward pass\n",
    "W.grad =None\n",
    "loss.backward() # loss=prob=counts/sum=counts=logit......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "52188de4-bfc7-4d7a-b51b-bb705a21d157",
   "metadata": {},
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad # gradient decesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "aef61886-5dc6-455c-960f-4da09046c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loop- [forward pass-backward pass-gradient descent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290286a3-7fdf-4a49-a271-e9321b773046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "6eaee330-9b79-41e3-a923-b792eac3ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of examples:  228146\n"
     ]
    }
   ],
   "source": [
    "# create the dataset\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2 in zip(chs, chs[1:]):\n",
    "    ix1 = stoi[ch1]\n",
    "    ix2 = stoi[ch2]\n",
    "    xs.append(ix1)\n",
    "    ys.append(ix2)\n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)\n",
    "\n",
    "# initialize the 'network'\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b5c01960-91a4-4220-b948-7c4f5b926034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3788046836853027\n",
      "3.1610894203186035\n",
      "3.027186393737793\n",
      "2.9344849586486816\n",
      "2.867231607437134\n",
      "2.816654920578003\n",
      "2.777147054672241\n",
      "2.7452547550201416\n",
      "2.7188308238983154\n",
      "2.696505546569824\n"
     ]
    }
   ],
   "source": [
    "# gradient descent\n",
    "for k in range(10):\n",
    "  \n",
    "  # forward pass\n",
    "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
    "  logits = xenc @ W # predict log-counts\n",
    "  counts = logits.exp() # counts, equivalent to N\n",
    "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()  ##w**2 is called regularization if w has all 0s in it\n",
    "  print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  W.grad = None # set to zero the gradient\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "d353db48-f18d-4a5f-9f99-374f11634cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss is almost same as count loss which we got earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "39275b09-675d-4caf-92c6-f8a4eb94e54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "janasah.\n",
      "p.\n",
      "cony.\n",
      "a.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    # xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    # logits = xenc @ W # predict log-counts\n",
    "    # counts = logits.exp() # counts, equivalent to N\n",
    "    # p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "105db2e9-09de-4ec1-bd31-81dd0e171174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here P is different in my code and seed is different but we both top and bottom will have same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "a073dd56-822a-44c1-8c47-ed861597b929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juwjde.\n",
      "janaqydjufhfbywe.\n",
      "nn.\n",
      "ksh.\n",
      "ritoleras.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(5):\n",
    "  \n",
    "  out = []\n",
    "  ix = 0\n",
    "  while True:\n",
    "    \n",
    "    # ----------\n",
    "    # BEFORE:\n",
    "    # p = P[ix]\n",
    "    # ----------\n",
    "    # NOW:\n",
    "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
    "    logits = xenc @ W # predict log-counts\n",
    "    counts = logits.exp() # counts, equivalent to N\n",
    "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
    "    # ----------\n",
    "    \n",
    "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix])\n",
    "    if ix == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c83c6-6de9-4383-b820-52409ce2e3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
