{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8b671b-edb9-4783-8868-73a3ee613b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4d114e9-ed03-4139-aee4-53208881fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba2e68f2-a375-4dfb-ba51-5b6d74790579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ava'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c6f4996-0db1-4a59-a7c6-9dfbd037c356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'v'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "601c7f0d-71de-4990-af29-970c2e588fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35bdbd68-3f1a-4e0c-84f6-c4da68f89d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i+1 for i,s in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2a02d3d2-db92-4861-a95a-060fbcda45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d10c05ce-6ba8-4495-b5aa-9a7e6c1af32b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... --> e\n",
      "..e --> m\n",
      ".em --> m\n",
      "emm --> a\n",
      "mma --> .\n",
      "... --> o\n",
      "..o --> l\n",
      ".ol --> i\n",
      "oli --> v\n",
      "liv --> i\n",
      "ivi --> a\n",
      "via --> .\n",
      "... --> a\n",
      "..a --> v\n",
      ".av --> a\n",
      "ava --> .\n",
      "... --> i\n",
      "..i --> s\n",
      ".is --> a\n",
      "isa --> b\n",
      "sab --> e\n",
      "abe --> l\n",
      "bel --> l\n",
      "ell --> a\n",
      "lla --> .\n",
      "... --> s\n",
      "..s --> o\n",
      ".so --> p\n",
      "sop --> h\n",
      "oph --> i\n",
      "phi --> a\n",
      "hia --> .\n",
      "[[0, 0, 0], [0, 0, 5], [0, 5, 13], [5, 13, 13], [13, 13, 1], [0, 0, 0], [0, 0, 15], [0, 15, 12], [15, 12, 9], [12, 9, 22], [9, 22, 9], [22, 9, 1], [0, 0, 0], [0, 0, 1], [0, 1, 22], [1, 22, 1], [0, 0, 0], [0, 0, 9], [0, 9, 19], [9, 19, 1], [19, 1, 2], [1, 2, 5], [2, 5, 12], [5, 12, 12], [12, 12, 1], [0, 0, 0], [0, 0, 19], [0, 19, 15], [19, 15, 16], [15, 16, 8], [16, 8, 9], [8, 9, 1]]\n",
      "tensor([[ 0,  0,  0],\n",
      "        [ 0,  0,  5],\n",
      "        [ 0,  5, 13],\n",
      "        [ 5, 13, 13],\n",
      "        [13, 13,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 15],\n",
      "        [ 0, 15, 12],\n",
      "        [15, 12,  9],\n",
      "        [12,  9, 22],\n",
      "        [ 9, 22,  9],\n",
      "        [22,  9,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  1],\n",
      "        [ 0,  1, 22],\n",
      "        [ 1, 22,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0,  9],\n",
      "        [ 0,  9, 19],\n",
      "        [ 9, 19,  1],\n",
      "        [19,  1,  2],\n",
      "        [ 1,  2,  5],\n",
      "        [ 2,  5, 12],\n",
      "        [ 5, 12, 12],\n",
      "        [12, 12,  1],\n",
      "        [ 0,  0,  0],\n",
      "        [ 0,  0, 19],\n",
      "        [ 0, 19, 15],\n",
      "        [19, 15, 16],\n",
      "        [15, 16,  8],\n",
      "        [16,  8,  9],\n",
      "        [ 8,  9,  1]])\n"
     ]
    }
   ],
   "source": [
    "blocksize=3\n",
    "X,Y = [],[]\n",
    "\n",
    "for w in words[:5]:\n",
    "    #print(w)\n",
    "    context = [0]*blocksize\n",
    "    for ch in w+'.':\n",
    "        # print(ch)\n",
    "        ix=stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #\n",
    "        print (''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "        context =context[1:]+[ix]\n",
    "print(X)\n",
    "X = torch.tensor(X)\n",
    "print(X)\n",
    "Y = torch.tensor(Y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160fd83a-3b7b-4f9d-929c-19efcd2fd5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=[0]*10\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "537e8d83-0aad-4d71-b246-b672ed075d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3]), torch.int64, torch.Size([32]), torch.int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b1f8d4d5-5db3-4f38-89b6-e6a160b71e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookup table\n",
    "\n",
    "C= torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8c6ea88f-163f-4e90-8349-165fbc45c85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2374, -0.8679],\n",
       "        [-0.2788,  1.2282],\n",
       "        [-2.8233,  0.6397],\n",
       "        [-1.0845, -2.7669],\n",
       "        [-0.4035,  0.6368],\n",
       "        [-0.5516, -0.2694],\n",
       "        [ 1.5011, -0.2377],\n",
       "        [ 0.2090,  0.1217],\n",
       "        [ 0.5346,  0.0618],\n",
       "        [-0.8681,  1.7609],\n",
       "        [-1.0644,  1.0225],\n",
       "        [ 1.2170, -0.1852],\n",
       "        [-0.2014,  0.8887],\n",
       "        [ 0.0588, -2.1722],\n",
       "        [-1.9443, -0.7860],\n",
       "        [ 1.2660,  1.3129],\n",
       "        [ 0.1812,  1.0343],\n",
       "        [-0.6800,  0.3471],\n",
       "        [-1.9825, -0.8652],\n",
       "        [-1.7578, -1.0175],\n",
       "        [ 0.0846, -0.6429],\n",
       "        [ 0.8926, -0.1261],\n",
       "        [ 0.3042, -2.1388],\n",
       "        [ 1.9180,  0.6863],\n",
       "        [ 1.1518,  0.1614],\n",
       "        [-1.4213,  0.1716],\n",
       "        [ 0.2499, -1.1691]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59562097-3835-4aba-89ba-5339000e043f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5516, -0.2694])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9f69aaa-ab86-410b-9216-f9360dfdc8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.one_hot(torch.tensor(5), num_classes=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b63a9f1c-078a-4015-8b64-9c3cbd87bbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5516, -0.2694])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " F.one_hot(torch.tensor(5), num_classes=27).float()@ C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f57a2bc-b93e-4114-9221-ed00a33ff2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5516, -0.2694],\n",
       "        [ 1.5011, -0.2377],\n",
       "        [ 0.2090,  0.1217]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[[5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "084032d7-22ec-4879-811e-a74b6f32cce2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0],\n",
       "        [ 0,  0,  5],\n",
       "        [ 0,  5, 13],\n",
       "        [ 5, 13, 13],\n",
       "        [13, 13,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 15],\n",
       "        [ 0, 15, 12],\n",
       "        [15, 12,  9],\n",
       "        [12,  9, 22],\n",
       "        [ 9, 22,  9],\n",
       "        [22,  9,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  1],\n",
       "        [ 0,  1, 22],\n",
       "        [ 1, 22,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0,  9],\n",
       "        [ 0,  9, 19],\n",
       "        [ 9, 19,  1],\n",
       "        [19,  1,  2],\n",
       "        [ 1,  2,  5],\n",
       "        [ 2,  5, 12],\n",
       "        [ 5, 12, 12],\n",
       "        [12, 12,  1],\n",
       "        [ 0,  0,  0],\n",
       "        [ 0,  0, 19],\n",
       "        [ 0, 19, 15],\n",
       "        [19, 15, 16],\n",
       "        [15, 16,  8],\n",
       "        [16,  8,  9],\n",
       "        [ 8,  9,  1]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a7547563-dea6-42ee-a9f7-1ff5b814f902",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [-0.5516, -0.2694]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [-0.5516, -0.2694],\n",
       "         [ 0.0588, -2.1722]],\n",
       "\n",
       "        [[-0.5516, -0.2694],\n",
       "         [ 0.0588, -2.1722],\n",
       "         [ 0.0588, -2.1722]],\n",
       "\n",
       "        [[ 0.0588, -2.1722],\n",
       "         [ 0.0588, -2.1722],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 1.2660,  1.3129]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 1.2660,  1.3129],\n",
       "         [-0.2014,  0.8887]],\n",
       "\n",
       "        [[ 1.2660,  1.3129],\n",
       "         [-0.2014,  0.8887],\n",
       "         [-0.8681,  1.7609]],\n",
       "\n",
       "        [[-0.2014,  0.8887],\n",
       "         [-0.8681,  1.7609],\n",
       "         [ 0.3042, -2.1388]],\n",
       "\n",
       "        [[-0.8681,  1.7609],\n",
       "         [ 0.3042, -2.1388],\n",
       "         [-0.8681,  1.7609]],\n",
       "\n",
       "        [[ 0.3042, -2.1388],\n",
       "         [-0.8681,  1.7609],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [-0.2788,  1.2282],\n",
       "         [ 0.3042, -2.1388]],\n",
       "\n",
       "        [[-0.2788,  1.2282],\n",
       "         [ 0.3042, -2.1388],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [-0.8681,  1.7609]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [-0.8681,  1.7609],\n",
       "         [-1.7578, -1.0175]],\n",
       "\n",
       "        [[-0.8681,  1.7609],\n",
       "         [-1.7578, -1.0175],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[-1.7578, -1.0175],\n",
       "         [-0.2788,  1.2282],\n",
       "         [-2.8233,  0.6397]],\n",
       "\n",
       "        [[-0.2788,  1.2282],\n",
       "         [-2.8233,  0.6397],\n",
       "         [-0.5516, -0.2694]],\n",
       "\n",
       "        [[-2.8233,  0.6397],\n",
       "         [-0.5516, -0.2694],\n",
       "         [-0.2014,  0.8887]],\n",
       "\n",
       "        [[-0.5516, -0.2694],\n",
       "         [-0.2014,  0.8887],\n",
       "         [-0.2014,  0.8887]],\n",
       "\n",
       "        [[-0.2014,  0.8887],\n",
       "         [-0.2014,  0.8887],\n",
       "         [-0.2788,  1.2282]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [ 0.2374, -0.8679],\n",
       "         [-1.7578, -1.0175]],\n",
       "\n",
       "        [[ 0.2374, -0.8679],\n",
       "         [-1.7578, -1.0175],\n",
       "         [ 1.2660,  1.3129]],\n",
       "\n",
       "        [[-1.7578, -1.0175],\n",
       "         [ 1.2660,  1.3129],\n",
       "         [ 0.1812,  1.0343]],\n",
       "\n",
       "        [[ 1.2660,  1.3129],\n",
       "         [ 0.1812,  1.0343],\n",
       "         [ 0.5346,  0.0618]],\n",
       "\n",
       "        [[ 0.1812,  1.0343],\n",
       "         [ 0.5346,  0.0618],\n",
       "         [-0.8681,  1.7609]],\n",
       "\n",
       "        [[ 0.5346,  0.0618],\n",
       "         [-0.8681,  1.7609],\n",
       "         [-0.2788,  1.2282]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "47b0a490-4dab-4051-99f3-a8c7e9ee3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb=C[X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9e85899-f32b-495f-981a-738eec95101e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 2])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45b410a8-768f-4cdd-99d3-a93835a9fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3*2=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "60693069-9d72-46e7-867b-af919ed6699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c10da-40e3-40fd-8797-f63ca4764b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb@w1+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2cd78a2-bdd4-4dfb-abde-5fde2ab00f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1= torch.randn((6,100))\n",
    "b1= torch.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4c253a34-49d6-4601-b2ab-b99a526194c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5116,  1.4578,  0.1976,  0.5708],\n",
       "        [ 1.1077, -0.2818, -1.4572,  0.5754],\n",
       "        [ 0.2145,  0.2935,  0.0215, -0.7241],\n",
       "        [ 0.5133,  1.9163,  0.4333,  0.6484],\n",
       "        [ 0.9235,  2.2075, -1.7004,  0.1253],\n",
       "        [ 0.8860, -1.8671,  1.0910,  0.3701]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e906462f-6989-464b-af1c-2950b83eda0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to match the dimension of emb and w1 we use view\n",
    "a=torch.arange(10)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "682d3605-1c5f-4af8-a81a-8de439af42f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3],\n",
       "        [4, 5],\n",
       "        [6, 7],\n",
       "        [8, 9]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7a9aded0-298c-4591-a6a0-32969ab2c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h= emb.view(32,6)@w1+b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d131a8d-35b3-4373-a87b-4a618a1d0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "h= emb.view(emb.shape[0],6)@w1+b1 #h= emb.view(-1,6)@w1+b1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2a5e425f-d775-4eda-955f-bffc793bd5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "acc76d07-f0e7-4037-87a1-0a9eb59332dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4365f263-4c64-455c-8fbe-b905302f4ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = torch.randn((100,27))\n",
    "b2= torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7c018e59-6afd-4e75-a21b-c0f5d1ae2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ w2 +b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "15ac6933-0615-4296-ada1-16c59353969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "70bc797c-5d9b-4bd2-a133-d6db5db3f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=counts/counts.sum(1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "01e19938-e415-4e01-8010-e9295dd395a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ed42e8af-ba03-46e0-ac68-ab3a82401419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f6640606-be4e-4988-8680-79a5e2188743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
       "         1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cfe0b6d7-94fc-4116-a2e3-9c3afbc4bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bdd6a10f-def4-4e3b-9095-c2145bc25d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1090e-18)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "81de4964-d0f8-44e1-ae19-a377c41b6694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1456e-29, 2.4528e-25, 2.6033e-34, 0.0000e+00, 1.0851e-10, 1.2958e-35,\n",
       "        6.6653e-24, 1.4808e-34, 9.3168e-20, 1.0816e-03, 1.8964e-32, 8.9701e-18,\n",
       "        5.9414e-22, 1.8090e-22, 1.7412e-25, 6.7448e-23, 4.4257e-35, 1.1204e-13,\n",
       "        8.5225e-12, 1.7976e-23, 3.1051e-19, 1.3400e-06, 1.0000e+00, 2.0594e-09,\n",
       "        3.5387e-13, 1.4845e-23, 9.4270e-29, 3.4817e-23, 2.3836e-07, 1.3446e-14,\n",
       "        9.3715e-09, 1.2139e-10])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob[torch.arange(32),Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6abe499b-84b2-40ad-a769-c5ecab98a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -prob[torch.arange(32),Y].log().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5fa43eb8-f291-4a11-829a-6edfdcec024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PUTTING ALL TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6b097995-812c-4eee-b9ef-bff1d0c7afce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "blocksize=3\n",
    "X,Y = [],[]\n",
    "\n",
    "for w in words:\n",
    "    #print(w)\n",
    "    context = [0]*blocksize\n",
    "    for ch in w+'.':\n",
    "        # print(ch)\n",
    "        ix=stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #\n",
    "        # print (''.join(itos[i] for i in context), '-->', itos[ix])\n",
    "        context =context[1:]+[ix]\n",
    "# print(X)\n",
    "X = torch.tensor(X)\n",
    "# print(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "59daf178-aa1b-46d2-9e60-ea44e3bdc96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.int64, torch.Size([228146]), torch.int64)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "a0ea6f9b-4ea1-439c-a797-eacf2769bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dbd58bdc-c9f5-4d0d-ba9c-5c66c0784a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4db43df2-673d-4890-8e4c-9911bd2b8931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "counts = logits.exp()\n",
    "prob=counts/counts.sum(1, keepdims=True)\n",
    "loss = -prob[torch.arange(32),Y].log().mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5848f58b-0ec0-4be1-8515-8b6b950d417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "# counts = logits.exp()\n",
    "# prob=counts/counts.sum(1, keepdims=True)\n",
    "# loss = -prob[torch.arange(32),Y].log().mean()\n",
    "loss = F.cross_entropy(logits,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fe8421fe-72b3-4976-9f0b-f813ee15fdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.7697)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ad713422-488a-48c5-b12d-3e2384ad54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_entropy is very use ful than the earlier mentod as its memory effocient and neumerical effieienct forward and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a920c16c-5ecc-40ff-8dc2-b877e205c108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0067, 1.0000, 0.1353,    inf])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits =torch.tensor([-5,0,-2,500])\n",
    "counts = logits.exp()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "69d8cabd-9bb0-468c-9a80-1944a580af74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 1.])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits =torch.tensor([-5,0,-2,500])-500\n",
    "counts = logits.exp()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e000246f-04dd-4d4d-bb03-272d91f249f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_entropy uses 2nd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "ab812ef6-567f-4b7a-abd4-506f0dab6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e19a7deb-e470-4ca5-9607-6846d2620f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.5052, grad_fn=<NllLossBackward0>)\n",
      "tensor(17.0845, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.7765, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.8333, grad_fn=<NllLossBackward0>)\n",
      "tensor(14.0026, grad_fn=<NllLossBackward0>)\n",
      "tensor(13.2533, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.5799, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.9831, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.4705, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.0519, grad_fn=<NllLossBackward0>)\n",
      "11.051864624023438\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "# forwardpass\n",
    "    emb = C[X] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits,Y)\n",
    "    print(loss)\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad=None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1* p.grad\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8d9feb04-2494-4b51-b29d-6cc84a60d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss is reducing easily as we have 3400 parameters and 32 examples . we are doing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "1f276175-a7cb-43fa-9832-e92301d8513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Processing - to run quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "dc4cda3e-e45a-42b0-8348-aa6844d86c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 1, 3, 3, 4, 1, 4, 1, 4, 2, 1, 4, 1, 4, 1, 3, 0, 3, 3, 1, 1, 1, 3,\n",
       "        2, 4, 0, 4, 4, 1, 2, 4])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,5,(32,))# 32 elements from 0-5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b3caa379-82c0-4d64-9c59-0f330214f25e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([167886, 183482,  58344, 134277,  52019, 203838, 148555,  98393, 164645,\n",
       "         67961,  23734, 123038,  34701,  14904, 225056, 195945, 171782,  10200,\n",
       "         41414,  81922, 214356,  10950,   1684,  32756,  51032,  73928, 210864,\n",
       "        138870, 178159, 150023, 114285,  51274])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,X.shape[0],(32,))# selecting random 32 elements and run the model on this batch of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b0091a4e-7e3c-48f2-b6e1-77a9df4fc501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4806,  0.5774],\n",
       "         [ 2.3819, -0.6509],\n",
       "         [ 2.3819, -0.6509]],\n",
       "\n",
       "        [[-0.4806,  0.5774],\n",
       "         [ 2.3819, -0.6509],\n",
       "         [ 2.3819, -0.6509]],\n",
       "\n",
       "        [[ 2.3819, -0.6509],\n",
       "         [ 2.3819, -0.6509],\n",
       "         [ 0.0902, -1.0768]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[X[[3,3,4]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "93e45b47-2c78-4f34-bfdd-d718864f5a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.5985, grad_fn=<NllLossBackward0>)\n",
      "tensor(18.6412, grad_fn=<NllLossBackward0>)\n",
      "tensor(16.4533, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.4423, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.0832, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.6260, grad_fn=<NllLossBackward0>)\n",
      "tensor(15.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(12.3243, grad_fn=<NllLossBackward0>)\n",
      "tensor(10.3950, grad_fn=<NllLossBackward0>)\n",
      "tensor(11.5743, grad_fn=<NllLossBackward0>)\n",
      "11.574263572692871\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    #minibatch\n",
    "    ix =torch.randint(0,X.shape[0],(32,))# selecting random 32 elements and run the model on this batch of 32\n",
    "    \n",
    "    # forwardpass\n",
    "    emb = C[X[ix]] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits,Y[ix])\n",
    "    print(loss)\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad=None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1* p.grad\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "48376f5b-6158-4a87-99d0-e469ec931dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# as we are having only 32 examples the gradient will not be consistently lower compared to 228146 X but this  process is quick and good estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "3179a203-8362-49ee-a1c3-0329551e33b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8737, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss for whole batch\n",
    "emb = C[X] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits,Y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "059fca4c-f7b0-44ad-a809-c46310d278b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learningrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "c156ab6b-5422-40d2-8e70-87da6bf38d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.1120, 0.2230, 0.3340, 0.4450, 0.5560, 0.6670, 0.7780, 0.8890,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0.001, 1,10) # give linerly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "a404755f-ec96-41d4-9a6a-c6287499e7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0010, 0.0022, 0.0046, 0.0100, 0.0215, 0.0464, 0.1000, 0.2154, 0.4642,\n",
       "        1.0000])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lre = torch.linspace(-3, 0,10)#10^-3 =0.001\n",
    "lrs = 10**lre\n",
    "lrs # spaced exponentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "49bd9632-20d4-4a6f-8f74-36892588d86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.5197, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.8887, grad_fn=<NllLossBackward0>)\n",
      "tensor(9.2668, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.0164, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.0321, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3275, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.6169, grad_fn=<NllLossBackward0>)\n",
      "tensor(8.5474, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.3330, grad_fn=<NllLossBackward0>)\n",
      "tensor(7.5935, grad_fn=<NllLossBackward0>)\n",
      "7.5934739112854\n"
     ]
    }
   ],
   "source": [
    "lri=[]\n",
    "lossi=[]\n",
    "for i in range(10):\n",
    "\n",
    "    #minibatch\n",
    "    ix =torch.randint(0,X.shape[0],(32,))# selecting random 32 elements and run the model on this batch of 32\n",
    "    \n",
    "    # forwardpass\n",
    "    emb = C[X[ix]] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits,Y[ix])\n",
    "    print(loss)\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad=None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    lr=lrs[i]\n",
    "    for p in parameters:\n",
    "        p.data += -lr* p.grad\n",
    "\n",
    "    #track ststs\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f77cf-185b-4715-9620-0b5cee235148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
