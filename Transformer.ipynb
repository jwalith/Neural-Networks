{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70532412-73ec-4bbb-b4f9-2f1c3920b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcc35e7-f582-4774-8df0-e94a881e0325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cf3c9c-fa3e-4128-8721-0f745bea1a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rathe'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cef0a11-17d1-4d63-8fb9-2b7f5b494b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rathe\n"
     ]
    }
   ],
   "source": [
    "print(text[:123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e7e8cd-3c08-4da7-a3ec-1d166a527af9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140b95cd-19e8-4e73-8c71-01cf66878fa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3acba5af-b0cd-484c-a611-4d8fb85ece2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabsize = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81daf0fe-c9ac-4773-818b-d06e019b4fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a891f469-a409-4577-b401-0cdf767a1e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f703108e-0745-4dc4-8849-e89c9edab28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {j:i for i,j in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8e72d9b-4238-4135-81df-e1b432ada5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = {i:j for i,j in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1752f5b3-5595-4f80-a16d-029933b3692a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode = lambda s:[stoi[c] for c in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba944888-f774-4726-b78d-4eafcbe9b84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31, 58, 43, 52, 45, 58, 46]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Stength\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6da81aff-ea9f-40a2-8303-728c3530e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda l:''.join([itos[c] for c in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aacc0d2d-66be-4e0d-92b8-8edf6a194f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stength'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([31, 58, 43, 52, 45, 58, 46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "33faab15-1e6b-4996-887b-969bdec682ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "931158b3-f8f0-4816-9a57-176ba0750d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([31, 58, 43, 52, 45, 58, 46])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([31, 58, 43, 52, 45, 58, 46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6791e2c-4d53-4951-af0f-9e86ee9c69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text) , dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58942395-0770-4446-9f06-b9ca28ce8512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1115394])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76d3ba96-2468-4d85-9633-6fac2d8a33fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eab324de-955e-4004-973f-a08516bf1c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citize'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe15b975-eba0-499e-a6b5-8f39973adb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "773f4e9b-d537-4ae6-8416-aee2077ddd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c9af088-ac40-4784-b5c2-4dd139ba1034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003854.6"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9*len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ee6ce8e-1359-47d2-a56e-39b05e3026b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data)) # 90% will be train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1c07df0-5065-494a-9af4-cc52d871aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:n]\n",
    "val_data =data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5552fffb-eb34-4f10-9c70-9d112c75167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only train with chunks of data not the entire data set\n",
    "# chunk = block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a08da229-1530-43fa-a1c6-f6fb311ec691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size =8\n",
    "train_data[:block_size+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b109e0c-4145-45af-aef5-3fe96a522438",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[:block_size+1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e2a51f0a-6ec4-496a-983c-15f2cf2abdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for n in range(2):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "840d418a-b0ce-4afa-a72a-267ecac0e73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7df5210b-23f0-4ed8-8561-e7237066a375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d66c0a45-0de9-4af9-9d4f-0229e031f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor([18]) and the target is 18\n",
      "input tensor([18, 47]) and the target is 47\n",
      "input tensor([18, 47, 56]) and the target is 56\n",
      "input tensor([18, 47, 56, 57]) and the target is 57\n",
      "input tensor([18, 47, 56, 57, 58]) and the target is 58\n",
      "input tensor([18, 47, 56, 57, 58,  1]) and the target is 1\n",
      "input tensor([18, 47, 56, 57, 58,  1, 15]) and the target is 15\n",
      "input tensor([18, 47, 56, 57, 58,  1, 15, 47]) and the target is 47\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"input {context} and the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a14048a9-07f1-444b-be1b-3af948d18ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "50fc3340-6796-4f0b-a456-acd18a000dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "some = nn.Embedding(19,19) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "244ebae8-503f-458c-9bfb-c095664b9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some = nn.Embedding(5,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b87758ab-3d2d-4237-9952-b355875435fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(19, 19)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a0edfef-885f-4321-9e16-436a8a263a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1703, -0.5275, -1.3014, -0.5515, -0.8238, -0.2609,  0.6238,  0.3719,\n",
       "         -0.7105, -0.5664,  0.6888, -0.0873,  0.1912,  1.2089,  0.3411,  0.7537,\n",
       "         -0.8407, -0.2893,  0.4662]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some(x[:1]) # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6377ce22-ab3b-4c6c-9d1d-6d6fa9826853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cb3f2fac-2c73-4946-96a8-b1f9a28725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.Embedding(19,19) :  some random embeddings of size \n",
    "# some(x[:1]) = some(18) = emb(18) = C[18] = C = torch.randn((27,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e06333c5-6db4-4909-8386-d92233d80201",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c41e73e0-77ce-413d-9987-a18894afe281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7, 13, 20, 16, 23,  1, 23,  2])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(32 - 8, (8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8bc98684-b412-477f-96f7-98e8bf1f5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1f925d21-cf1c-46a6-bba3-b1ad799505c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[50, 39, 52, 63,  1, 47, 58, 57],\n",
      "        [56, 53, 63,  1, 42, 47, 42,  1],\n",
      "        [39, 51,  1, 39, 44, 56, 39, 47],\n",
      "        [17, 24, 21, 38, 13, 14, 17, 32]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[39, 52, 63,  1, 47, 58, 57, 43],\n",
      "        [53, 63,  1, 42, 47, 42,  1, 57],\n",
      "        [51,  1, 39, 44, 56, 39, 47, 42],\n",
      "        [24, 21, 38, 13, 14, 17, 32, 20]])\n"
     ]
    }
   ],
   "source": [
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1d6b0a04-b9b8-4f39-9eec-773007ba7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "aa7033d4-b84f-4893-8423-d5282736904b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [4, 65], got [4, 8]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[168], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m logits , loss\n\u001b[0;32m     14\u001b[0m m \u001b[38;5;241m=\u001b[39m Bigram(vocabsize)\n\u001b[1;32m---> 15\u001b[0m m(xb, yb)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[168], line 8\u001b[0m, in \u001b[0;36mBigram.forward\u001b[1;34m(self, ip, targets)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ip , targets ):\n\u001b[0;32m      6\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_emb(ip)\n\u001b[1;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, targets)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits , loss\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\n\u001b[0;32m   3495\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3496\u001b[0m     target,\n\u001b[0;32m   3497\u001b[0m     weight,\n\u001b[0;32m   3498\u001b[0m     _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction),\n\u001b[0;32m   3499\u001b[0m     ignore_index,\n\u001b[0;32m   3500\u001b[0m     label_smoothing,\n\u001b[0;32m   3501\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected target size [4, 65], got [4, 8]"
     ]
    }
   ],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocabsize, vocabsize)\n",
    "    def forward(self, ip , targets ):\n",
    "        logits = self.token_emb(ip)\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "37f6c4de-f51a-45a9-918e-6203a2e4f778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4992, -0.5556, -0.9414,  ...,  0.5055, -1.1229, -1.3802],\n",
       "         [ 1.1147,  0.7647,  0.5261,  ..., -0.9591, -1.1795,  0.6583],\n",
       "         [-1.2560,  1.6354, -0.1907,  ..., -1.1943, -1.0856, -0.1341],\n",
       "         ...,\n",
       "         [-0.8533,  0.9364,  1.1155,  ..., -1.3117,  0.9402, -1.3130],\n",
       "         [-0.7666, -1.9362, -0.4154,  ..., -2.0552,  0.0795, -0.0468],\n",
       "         [ 1.5458,  0.9108,  1.2844,  ...,  0.1039, -0.7675, -2.0384]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.3659, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocabsize, vocabsize)\n",
    "    def forward(self, ip , targets ):\n",
    "        logits = self.token_emb(ip)\n",
    "        B, T ,C = logits.shape\n",
    "        logits = logits.view(B*T,C)\n",
    "        targets = targets.view(B*T)\n",
    "\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "ebf14818-1dc4-4d46-80c1-29555182e58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.174387269895637"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(1/65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b225f1c1-a2e0-4ee5-9a13-aedc05ea3eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6172,  0.4670, -1.2181,  ...,  0.5254,  1.9695, -2.1321],\n",
       "         [ 0.2342, -1.9451,  1.4819,  ...,  0.2049, -0.4716, -1.7436],\n",
       "         [ 0.1686, -0.2249,  2.1984,  ..., -0.0740, -0.7982,  0.9283],\n",
       "         ...,\n",
       "         [-0.2485, -0.3359,  0.2612,  ..., -0.1945, -0.5056, -1.9642],\n",
       "         [-0.1597, -1.5145,  1.5969,  ...,  0.9335,  0.1614, -2.3761],\n",
       "         [ 1.0251, -2.6250, -1.5253,  ..., -0.3634, -1.1481,  0.6194]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(5.0191, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocabsize, vocabsize)\n",
    "    def forward(self, ip , targets=None ):\n",
    "        logits = self.token_emb(ip)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(ip)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a2b82136-b7aa-49a0-810f-999cc36ff2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ZQNhqCJ\n",
      "yYSAqbs$:y's,:mrSwgt\n",
      "p'xWSev-sHERhM-z&AcO'NDUTW hCk33!LfF?wuCwTvaKgC3n!QouPsv Vew?iSeitYMrw-\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(ip = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7c024ff5-6345-452d-b3a5-0ed773e75093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((1, 1), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "643297f2-f3bc-400d-98a5-03091a941053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6b345635-8381-416a-be9e-7c6d662c4125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2242, -1.3448,  1.0039,  ..., -1.2887,  0.9148, -1.1814],\n",
       "         [ 0.2700,  0.5150,  2.3193,  ..., -0.0704, -1.3662, -0.2126],\n",
       "         [-0.1900,  0.5618,  0.3003,  ..., -1.1355, -1.2173,  0.1022],\n",
       "         ...,\n",
       "         [-0.5602, -0.7079,  0.6190,  ...,  0.1465, -1.7353, -0.2495],\n",
       "         [ 0.0817,  0.4818,  0.0517,  ..., -0.7088,  2.7309, -0.6004],\n",
       "         [-0.5982,  2.0037, -0.2080,  ...,  0.1363, -2.4209, -2.4576]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.4550, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocabsize, vocabsize)\n",
    "    def forward(self, ip , targets=None ):\n",
    "        logits = self.token_emb(ip)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(ip)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            print(logits)\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            print(probs)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            print(ip_next)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "            print(ip)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3b8c21f2-b650-4555-a317-309659cec5af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7926, -0.4934, -0.5571,  0.3043, -0.3415,  0.0370, -0.3436,  1.2193,\n",
      "         -1.9131, -0.7418, -0.5473, -0.1534,  0.5742,  0.4423, -0.0723, -0.3840,\n",
      "         -1.6930, -0.8391, -1.0826,  0.0718, -0.7146, -0.4216,  0.0734,  0.4637,\n",
      "         -0.5090, -0.7130, -1.0143,  0.3516, -1.4997, -0.2790,  1.3459,  0.3984,\n",
      "         -2.0686,  0.6025, -0.1272,  0.8449, -1.3304, -1.4165, -0.4636,  1.5375,\n",
      "         -0.5974, -0.5451, -0.5291,  0.2046, -0.1251, -0.1885,  0.6401,  1.6612,\n",
      "          0.6052, -0.3046, -0.0848, -0.1670,  1.2124, -0.1693,  0.3510,  1.9829,\n",
      "         -0.0544,  1.3869, -0.4092, -0.6779,  0.3427, -1.5989,  0.8889,  0.1382,\n",
      "          0.8610]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0256, 0.0071, 0.0066, 0.0157, 0.0082, 0.0120, 0.0082, 0.0392, 0.0017,\n",
      "         0.0055, 0.0067, 0.0099, 0.0206, 0.0180, 0.0108, 0.0079, 0.0021, 0.0050,\n",
      "         0.0039, 0.0125, 0.0057, 0.0076, 0.0125, 0.0184, 0.0070, 0.0057, 0.0042,\n",
      "         0.0165, 0.0026, 0.0088, 0.0445, 0.0173, 0.0015, 0.0212, 0.0102, 0.0270,\n",
      "         0.0031, 0.0028, 0.0073, 0.0539, 0.0064, 0.0067, 0.0068, 0.0142, 0.0102,\n",
      "         0.0096, 0.0220, 0.0610, 0.0212, 0.0085, 0.0106, 0.0098, 0.0390, 0.0098,\n",
      "         0.0165, 0.0842, 0.0110, 0.0464, 0.0077, 0.0059, 0.0163, 0.0023, 0.0282,\n",
      "         0.0133, 0.0274]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[62]])\n",
      "tensor([[ 0, 62]])\n",
      "tensor([[ 0.7734, -0.1115, -0.5127,  0.3177,  0.4425, -0.4914, -0.0807,  0.8591,\n",
      "          0.3747,  1.1709,  1.2109, -0.9384, -1.4206,  0.1703,  0.0398, -0.7024,\n",
      "         -0.0400, -0.0075,  1.1213,  0.4914, -1.5063,  0.5844,  0.6578,  1.3599,\n",
      "          0.5956,  0.5431,  1.8420,  1.3178, -0.2890, -2.2204, -0.3805,  0.0600,\n",
      "          0.5010, -0.2537,  0.1363, -0.6462,  1.2733, -2.3855,  1.3218, -1.5399,\n",
      "          0.0196,  0.2942, -0.0160, -0.3340,  1.1991, -1.8501, -1.1205, -0.6579,\n",
      "         -0.5830,  0.7193,  1.1501, -0.3175,  0.6692,  0.5188,  0.2322,  0.4578,\n",
      "         -0.1166, -0.7107, -0.3030, -0.0382, -1.3059, -0.6198,  2.1622,  0.5028,\n",
      "         -2.3654]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0217, 0.0089, 0.0060, 0.0137, 0.0156, 0.0061, 0.0092, 0.0236, 0.0146,\n",
      "         0.0323, 0.0336, 0.0039, 0.0024, 0.0119, 0.0104, 0.0050, 0.0096, 0.0099,\n",
      "         0.0307, 0.0164, 0.0022, 0.0179, 0.0193, 0.0390, 0.0181, 0.0172, 0.0631,\n",
      "         0.0374, 0.0075, 0.0011, 0.0068, 0.0106, 0.0165, 0.0078, 0.0115, 0.0052,\n",
      "         0.0357, 0.0009, 0.0375, 0.0021, 0.0102, 0.0134, 0.0098, 0.0072, 0.0332,\n",
      "         0.0016, 0.0033, 0.0052, 0.0056, 0.0205, 0.0316, 0.0073, 0.0195, 0.0168,\n",
      "         0.0126, 0.0158, 0.0089, 0.0049, 0.0074, 0.0096, 0.0027, 0.0054, 0.0869,\n",
      "         0.0165, 0.0009]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[17]])\n",
      "tensor([[ 0, 62, 17]])\n",
      "tensor([[ 0.0817,  0.4818,  0.0517,  0.5056, -0.8117,  0.4296,  0.3190,  0.2151,\n",
      "          1.7622,  0.3322, -0.2397, -1.3363,  0.7268, -2.3508,  0.4275, -0.4432,\n",
      "          0.9646, -1.2703, -1.2404,  0.6640, -2.4352,  0.8465, -0.0346, -0.1891,\n",
      "          1.0447,  2.4966, -1.9624, -0.0273, -0.4079,  0.1493, -0.2327,  2.4739,\n",
      "          0.8558,  0.4004,  1.2903,  0.4896, -0.4929, -0.6918, -0.8803, -0.4649,\n",
      "          0.6498, -0.0439,  0.4484, -0.4469, -1.1216,  1.8059,  0.6759, -0.9161,\n",
      "         -0.1723, -0.3094,  1.1217, -1.0995,  1.9974,  1.0299,  0.4407,  0.8770,\n",
      "         -0.1421,  0.6960, -0.4866,  1.1212, -0.0175,  1.1101, -0.7088,  2.7309,\n",
      "         -0.6004]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0081, 0.0121, 0.0079, 0.0124, 0.0033, 0.0115, 0.0103, 0.0093, 0.0436,\n",
      "         0.0104, 0.0059, 0.0020, 0.0155, 0.0007, 0.0115, 0.0048, 0.0196, 0.0021,\n",
      "         0.0022, 0.0145, 0.0007, 0.0174, 0.0072, 0.0062, 0.0213, 0.0908, 0.0011,\n",
      "         0.0073, 0.0050, 0.0087, 0.0059, 0.0887, 0.0176, 0.0112, 0.0272, 0.0122,\n",
      "         0.0046, 0.0037, 0.0031, 0.0047, 0.0143, 0.0072, 0.0117, 0.0048, 0.0024,\n",
      "         0.0455, 0.0147, 0.0030, 0.0063, 0.0055, 0.0230, 0.0025, 0.0551, 0.0209,\n",
      "         0.0116, 0.0180, 0.0065, 0.0150, 0.0046, 0.0229, 0.0073, 0.0227, 0.0037,\n",
      "         0.1147, 0.0041]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[31]])\n",
      "tensor([[ 0, 62, 17, 31]])\n",
      "tensor([[ 0.4027,  1.1117,  1.4502,  0.6342, -0.5841,  0.4782, -0.3590, -0.0782,\n",
      "         -2.0452, -0.6606,  0.5197,  0.4064, -0.4998, -0.7389,  1.6159, -0.0366,\n",
      "          0.5571,  0.2556, -0.1340,  0.8342,  0.3182, -1.2770, -0.8634, -0.1533,\n",
      "         -0.4471,  1.1043, -0.1312,  0.1768,  0.1832,  1.2384, -1.4509, -1.4034,\n",
      "          1.9611, -0.7568,  1.4309,  0.1939,  0.0237, -2.1565, -0.3808,  0.8332,\n",
      "         -0.3503, -0.5525, -0.6272,  0.0660, -0.3414, -1.4279,  0.8940, -0.3539,\n",
      "          0.4331,  0.2795,  0.2011,  0.9628,  0.9599, -0.6785,  0.3408,  1.4859,\n",
      "         -0.1544,  1.9923, -1.2498,  2.1751, -0.2908, -0.2936, -0.2153, -1.0519,\n",
      "          1.0584]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0139, 0.0282, 0.0395, 0.0175, 0.0052, 0.0149, 0.0065, 0.0086, 0.0012,\n",
      "         0.0048, 0.0156, 0.0139, 0.0056, 0.0044, 0.0466, 0.0089, 0.0162, 0.0120,\n",
      "         0.0081, 0.0213, 0.0127, 0.0026, 0.0039, 0.0079, 0.0059, 0.0280, 0.0081,\n",
      "         0.0111, 0.0111, 0.0320, 0.0022, 0.0023, 0.0659, 0.0043, 0.0388, 0.0112,\n",
      "         0.0095, 0.0011, 0.0063, 0.0213, 0.0065, 0.0053, 0.0049, 0.0099, 0.0066,\n",
      "         0.0022, 0.0227, 0.0065, 0.0143, 0.0123, 0.0113, 0.0243, 0.0242, 0.0047,\n",
      "         0.0130, 0.0409, 0.0079, 0.0679, 0.0027, 0.0816, 0.0069, 0.0069, 0.0075,\n",
      "         0.0032, 0.0267]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[57]])\n",
      "tensor([[ 0, 62, 17, 31, 57]])\n",
      "tensor([[-1.0974,  1.2223,  0.3726,  0.1841, -0.3205, -0.2870,  0.0092,  0.5307,\n",
      "         -0.7257, -0.3478,  0.9992,  0.0662,  0.9859, -0.5746, -0.6364,  0.1542,\n",
      "          0.1750, -1.4243, -0.0078, -0.4688,  0.8223, -0.6539,  0.3155, -0.8620,\n",
      "          0.7058,  0.6104, -0.7742,  1.1057, -0.9387,  2.5462,  0.7771,  0.3197,\n",
      "         -0.3213, -0.5422,  0.3466,  0.5390,  1.8914, -1.1059,  1.1030,  1.0181,\n",
      "          1.7685, -0.9007, -0.6289,  0.5848, -0.1079,  0.9028, -0.3207,  0.7940,\n",
      "          0.1085, -1.6153,  0.3592,  0.5552, -0.2764,  0.1085, -0.3882, -1.5310,\n",
      "         -0.9485,  1.0446, -1.5310, -0.6813,  0.2420, -0.4030, -0.9979, -0.1898,\n",
      "         -1.3436]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0034, 0.0343, 0.0147, 0.0122, 0.0073, 0.0076, 0.0102, 0.0172, 0.0049,\n",
      "         0.0071, 0.0275, 0.0108, 0.0271, 0.0057, 0.0054, 0.0118, 0.0121, 0.0024,\n",
      "         0.0100, 0.0063, 0.0230, 0.0053, 0.0139, 0.0043, 0.0205, 0.0186, 0.0047,\n",
      "         0.0306, 0.0040, 0.1291, 0.0220, 0.0139, 0.0073, 0.0059, 0.0143, 0.0173,\n",
      "         0.0671, 0.0033, 0.0305, 0.0280, 0.0593, 0.0041, 0.0054, 0.0182, 0.0091,\n",
      "         0.0250, 0.0073, 0.0224, 0.0113, 0.0020, 0.0145, 0.0176, 0.0077, 0.0113,\n",
      "         0.0069, 0.0022, 0.0039, 0.0288, 0.0022, 0.0051, 0.0129, 0.0068, 0.0037,\n",
      "         0.0084, 0.0026]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[60]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60]])\n",
      "tensor([[-0.0858, -1.1218, -1.3702,  0.5904,  0.5223, -0.3150,  0.8505, -2.0155,\n",
      "         -0.2628, -0.5300,  1.8044, -0.2204, -0.6381, -1.2577, -2.3918, -0.6176,\n",
      "          0.8322, -0.7198,  1.2411, -0.5693,  2.0907, -0.1090, -1.1185,  1.0123,\n",
      "         -1.3535, -0.2263, -1.6315, -0.0067, -0.1412,  0.2161, -0.6444,  1.3829,\n",
      "         -0.3038, -1.4169, -0.3794,  0.2905,  1.4462, -1.4416,  0.6174, -1.0996,\n",
      "         -0.5516, -0.4349,  1.1850,  0.4131, -0.5903,  2.2812,  0.4225, -0.9378,\n",
      "          1.0944, -1.0123, -0.5928, -1.6397, -0.8475,  1.8102,  0.0559,  1.0427,\n",
      "          0.4377,  0.1451,  0.5362, -0.8133, -1.0631, -0.1685, -0.0112, -0.2657,\n",
      "         -0.2666]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0095, 0.0034, 0.0026, 0.0187, 0.0174, 0.0076, 0.0242, 0.0014, 0.0080,\n",
      "         0.0061, 0.0629, 0.0083, 0.0055, 0.0029, 0.0009, 0.0056, 0.0238, 0.0050,\n",
      "         0.0358, 0.0059, 0.0837, 0.0093, 0.0034, 0.0285, 0.0027, 0.0083, 0.0020,\n",
      "         0.0103, 0.0090, 0.0128, 0.0054, 0.0412, 0.0076, 0.0025, 0.0071, 0.0138,\n",
      "         0.0439, 0.0024, 0.0192, 0.0034, 0.0060, 0.0067, 0.0338, 0.0156, 0.0057,\n",
      "         0.1013, 0.0158, 0.0041, 0.0309, 0.0038, 0.0057, 0.0020, 0.0044, 0.0632,\n",
      "         0.0109, 0.0293, 0.0160, 0.0120, 0.0177, 0.0046, 0.0036, 0.0087, 0.0102,\n",
      "         0.0079, 0.0079]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[18]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60, 18]])\n",
      "tensor([[ 0.8637,  0.1332,  0.6526, -1.8274, -0.8788, -0.5588, -0.3822, -1.4103,\n",
      "          0.7724, -0.0208, -0.0966, -1.1683,  1.0162,  1.3325,  1.1023,  0.6093,\n",
      "         -0.3643,  0.3796, -0.6880,  1.4874,  1.0788,  0.1360, -0.0120,  0.0341,\n",
      "         -0.6738, -0.2203,  0.0919, -1.0289, -1.6335,  1.9204, -0.7811, -0.0446,\n",
      "          0.4359,  0.3928,  0.5118,  0.6601,  1.3258,  2.9387,  1.1153,  0.9227,\n",
      "         -1.2686,  0.0093,  0.0856,  0.7381,  0.3774, -0.1310,  0.4554, -0.9620,\n",
      "         -0.4069,  0.0371, -1.4247,  1.1659,  0.3845, -2.6859, -1.7621, -1.3589,\n",
      "         -1.2080, -1.6965, -0.4260, -0.1319,  1.2062, -0.1713, -0.3814,  1.2600,\n",
      "          1.1356]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0212, 0.0102, 0.0172, 0.0014, 0.0037, 0.0051, 0.0061, 0.0022, 0.0193,\n",
      "         0.0088, 0.0081, 0.0028, 0.0247, 0.0339, 0.0269, 0.0164, 0.0062, 0.0131,\n",
      "         0.0045, 0.0395, 0.0263, 0.0102, 0.0088, 0.0092, 0.0046, 0.0072, 0.0098,\n",
      "         0.0032, 0.0017, 0.0610, 0.0041, 0.0085, 0.0138, 0.0132, 0.0149, 0.0173,\n",
      "         0.0336, 0.1688, 0.0273, 0.0225, 0.0025, 0.0090, 0.0097, 0.0187, 0.0130,\n",
      "         0.0078, 0.0141, 0.0034, 0.0059, 0.0093, 0.0021, 0.0287, 0.0131, 0.0006,\n",
      "         0.0015, 0.0023, 0.0027, 0.0016, 0.0058, 0.0078, 0.0298, 0.0075, 0.0061,\n",
      "         0.0315, 0.0278]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[46]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60, 18, 46]])\n",
      "tensor([[-9.7166e-01, -2.1986e+00, -1.9003e+00,  4.0737e-01,  1.3102e+00,\n",
      "         -1.4808e+00, -6.7875e-01,  4.1325e-01,  2.4097e-02, -2.8749e-01,\n",
      "         -1.5074e+00, -1.4923e+00, -6.2164e-01,  3.4244e-01,  2.8062e-01,\n",
      "         -7.6396e-01,  1.2537e+00,  6.4440e-02, -4.9200e-02,  1.0445e-01,\n",
      "          2.0913e+00, -1.3008e+00,  1.7308e+00, -9.8360e-01, -5.1389e-01,\n",
      "         -8.0881e-01,  5.5035e-01, -6.6771e-01, -4.0633e-01,  3.3848e-01,\n",
      "         -1.5966e+00, -7.2841e-02,  5.8560e-02,  1.5288e-01, -6.5879e-01,\n",
      "         -3.9953e-01, -5.6228e-01, -1.0649e+00, -1.2121e+00, -1.5810e-03,\n",
      "         -1.4950e-01,  1.1068e+00,  1.9978e-01, -3.2381e+00,  6.6824e-01,\n",
      "         -9.2632e-01, -1.1367e+00,  1.1598e+00, -1.5501e-02,  1.7885e+00,\n",
      "          4.2636e-01, -4.8867e-01, -6.9286e-01,  3.5420e-01,  5.3516e-02,\n",
      "         -2.0604e-01,  5.3445e-01, -1.4344e+00,  2.0598e+00,  8.8661e-01,\n",
      "          1.5669e+00,  8.5967e-01, -2.4476e-01,  5.3696e-01,  1.1715e+00]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0039, 0.0012, 0.0016, 0.0156, 0.0385, 0.0024, 0.0053, 0.0157, 0.0107,\n",
      "         0.0078, 0.0023, 0.0023, 0.0056, 0.0146, 0.0138, 0.0048, 0.0364, 0.0111,\n",
      "         0.0099, 0.0115, 0.0842, 0.0028, 0.0587, 0.0039, 0.0062, 0.0046, 0.0180,\n",
      "         0.0053, 0.0069, 0.0146, 0.0021, 0.0097, 0.0110, 0.0121, 0.0054, 0.0070,\n",
      "         0.0059, 0.0036, 0.0031, 0.0104, 0.0090, 0.0314, 0.0127, 0.0004, 0.0203,\n",
      "         0.0041, 0.0033, 0.0332, 0.0102, 0.0622, 0.0159, 0.0064, 0.0052, 0.0148,\n",
      "         0.0110, 0.0085, 0.0177, 0.0025, 0.0816, 0.0252, 0.0498, 0.0246, 0.0081,\n",
      "         0.0178, 0.0335]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[4]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60, 18, 46,  4]])\n",
      "tensor([[-0.5591,  0.7518, -0.7045, -0.1667, -0.2680, -0.5115,  0.9633,  0.6232,\n",
      "         -1.4634, -1.8643, -0.1331, -0.7286, -0.2102, -0.9724, -1.2486, -0.3962,\n",
      "          0.5122,  1.0781, -0.6139, -0.6716,  0.9843,  0.4561,  0.9792, -0.7263,\n",
      "         -0.3717,  0.7271,  0.0591, -1.2265, -0.2820,  1.4725, -0.4278,  0.5518,\n",
      "          2.7333,  1.3613, -2.5029, -0.6666,  1.5316,  0.3560, -0.4820,  1.0183,\n",
      "         -0.1493,  0.7201, -1.1934, -1.2736, -0.9064, -0.5381,  1.3665,  1.2043,\n",
      "          0.2526, -2.2047,  0.1995, -1.4068,  0.0600, -0.2181, -0.4268, -1.2704,\n",
      "         -1.9685,  1.4636, -0.7682,  0.0640, -0.3160, -0.8547,  1.1148, -0.8983,\n",
      "          0.1238]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0059, 0.0219, 0.0051, 0.0087, 0.0079, 0.0062, 0.0270, 0.0192, 0.0024,\n",
      "         0.0016, 0.0090, 0.0050, 0.0084, 0.0039, 0.0030, 0.0069, 0.0172, 0.0303,\n",
      "         0.0056, 0.0053, 0.0276, 0.0163, 0.0275, 0.0050, 0.0071, 0.0214, 0.0109,\n",
      "         0.0030, 0.0078, 0.0450, 0.0067, 0.0179, 0.1587, 0.0403, 0.0008, 0.0053,\n",
      "         0.0477, 0.0147, 0.0064, 0.0286, 0.0089, 0.0212, 0.0031, 0.0029, 0.0042,\n",
      "         0.0060, 0.0405, 0.0344, 0.0133, 0.0011, 0.0126, 0.0025, 0.0110, 0.0083,\n",
      "         0.0067, 0.0029, 0.0014, 0.0446, 0.0048, 0.0110, 0.0075, 0.0044, 0.0315,\n",
      "         0.0042, 0.0117]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[32]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60, 18, 46,  4, 32]])\n",
      "tensor([[-0.5982,  2.0037, -0.2080, -0.8261,  0.7745, -0.6426,  0.2281, -2.0049,\n",
      "          0.7567, -1.3653, -1.3911, -0.6907, -0.7003, -0.9535,  0.4341, -0.2430,\n",
      "          0.7746,  0.7325,  1.0594, -0.1996,  0.9212, -1.8676,  0.5601, -0.0139,\n",
      "          0.5676, -0.4092, -0.5657,  0.7451, -0.1631, -1.7132,  0.5156,  1.3631,\n",
      "          0.4931, -2.0570, -1.2629,  0.8897, -0.2039, -0.0345,  0.2207,  1.0491,\n",
      "          0.2621,  0.2642,  0.9873,  1.5610,  0.2649,  0.6178, -0.7248,  0.0292,\n",
      "          1.4071, -0.4727,  1.1882,  1.3042,  0.3649,  0.1165,  0.4700,  1.7336,\n",
      "         -1.0870,  0.0417,  0.5326, -0.5784,  0.1601,  1.0048,  0.1363, -2.4209,\n",
      "         -2.4576]], grad_fn=<SliceBackward0>)\n",
      "tensor([[0.0055, 0.0740, 0.0081, 0.0044, 0.0217, 0.0053, 0.0125, 0.0013, 0.0213,\n",
      "         0.0025, 0.0025, 0.0050, 0.0050, 0.0038, 0.0154, 0.0078, 0.0217, 0.0208,\n",
      "         0.0288, 0.0082, 0.0251, 0.0015, 0.0175, 0.0098, 0.0176, 0.0066, 0.0057,\n",
      "         0.0210, 0.0085, 0.0018, 0.0167, 0.0390, 0.0163, 0.0013, 0.0028, 0.0243,\n",
      "         0.0081, 0.0096, 0.0124, 0.0285, 0.0130, 0.0130, 0.0268, 0.0476, 0.0130,\n",
      "         0.0185, 0.0048, 0.0103, 0.0408, 0.0062, 0.0328, 0.0368, 0.0144, 0.0112,\n",
      "         0.0160, 0.0565, 0.0034, 0.0104, 0.0170, 0.0056, 0.0117, 0.0273, 0.0114,\n",
      "         0.0009, 0.0009]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[17]])\n",
      "tensor([[ 0, 62, 17, 31, 57, 60, 18, 46,  4, 32, 17]])\n",
      "\n",
      "xESsvFh&TE\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(ip = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=10)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8019e1ee-23e4-43fd-abab-3b7a7a84b635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.8310,  0.1300, -1.1649,  ...,  0.5579, -0.4868,  0.4926],\n",
       "         [-0.4426,  2.3768, -0.1844,  ...,  2.0336, -0.8147, -1.1484],\n",
       "         [-0.7087, -1.5436, -0.4889,  ...,  1.4503, -0.4070, -0.8518],\n",
       "         ...,\n",
       "         [-1.3701, -1.1324, -1.2795,  ..., -1.3980,  0.5840, -0.1136],\n",
       "         [ 0.1023,  0.2324, -0.4771,  ..., -1.7406, -1.1865, -0.6552],\n",
       "         [-0.6161,  0.1592, -0.0418,  ..., -1.1270,  0.2535,  0.2040]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.6431, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocabsize, vocabsize)\n",
    "    def forward(self, ip , targets=None ):\n",
    "        logits = self.token_emb(ip)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(ip)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2e2084fa-a02b-409d-a82a-63bfde1829fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5134dc12-22c4-48af-a935-15f25535e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "01631632-a25c-4f33-af70-7f9a62b09a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4092, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for steps in range(10000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "957726f8-d7a4-4a6a-9533-b483047fb48c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RDYDWh d hepe tivedst s thes ghuanghbre thil sut oure, tl ouer EROLOUSTIw ourpery ANCI rass,\n",
      "Wid?\n",
      "F\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(ip = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aa83eb77-cc22-459e-82c5-237c7dc1004c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d2389633-f610-4744-9c07-dd4afb9ae08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "51d15d74-51ef-45dc-8012-06b15d864902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb): Embedding(65, 65)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "c0489d3e-1081-4963-af38-94a2a81b8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "?Yfz?AikRZkNwc.wj,ZTkO-FT,yCtK\n",
      "q:!rLCkPBbqBUHe.XSvgO-3 SMGj?gc3aUqXbYH AtQgMNuTq&JthG.tSfFddXl!hHaLe\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(ip = torch.zeros((1, 1), dtype=torch.long, device=device), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf0c0f-7623-4887-9258-6387847b89b0",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "bd79d031-ed00-42b2-b928-b1e5cca488c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B,T,C = 4,8,2\n",
    "x=torch.randn(B,T,C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "968f557e-010e-43ae-9d47-5aef52f9ba1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7547, -0.2010],\n",
       "         [-0.3782,  1.0409],\n",
       "         [-1.8695,  1.4091],\n",
       "         [ 0.5646, -0.6764],\n",
       "         [ 0.5017,  0.3483],\n",
       "         [ 0.2702, -1.6603],\n",
       "         [ 1.0728,  0.6532],\n",
       "         [-0.3484, -0.2632]],\n",
       "\n",
       "        [[ 0.9006, -1.8652],\n",
       "         [-0.5501, -0.6626],\n",
       "         [ 0.7592,  0.1089],\n",
       "         [ 2.0645, -1.2541],\n",
       "         [ 0.3956,  0.4751],\n",
       "         [-0.0936, -0.5730],\n",
       "         [-0.9944,  1.8074],\n",
       "         [ 0.2255,  0.1344]],\n",
       "\n",
       "        [[-0.2598, -0.3317],\n",
       "         [ 0.2633, -0.4496],\n",
       "         [-1.4718, -0.9949],\n",
       "         [-1.7038, -0.7425],\n",
       "         [ 1.1787, -0.0136],\n",
       "         [ 0.0084, -1.1063],\n",
       "         [ 0.0781,  0.3678],\n",
       "         [-0.3091, -0.5354]],\n",
       "\n",
       "        [[-0.4665, -1.3891],\n",
       "         [-0.5641, -1.1680],\n",
       "         [ 1.2953, -1.1608],\n",
       "         [-0.6370, -1.0931],\n",
       "         [ 0.5531,  0.2289],\n",
       "         [ 2.4018, -0.1149],\n",
       "         [-0.8258, -0.5164],\n",
       "         [ 0.1412,  1.5448]]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "3e57a184-fb08-4391-aa74-521560040cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "5ced0806-fb58-40ef-b72c-a0cd4e9726b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way to communicate the tokens is to average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "146e75df-edc8-4069-8e4d-933cdcd07d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0645, -1.2541])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "fa3f449c-d91b-4f43-b1ae-362cad025c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9006, -1.8652],\n",
       "        [-0.5501, -0.6626],\n",
       "        [ 0.7592,  0.1089]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,:2+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb9800-e343-4856-94d3-0a6831a70afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "aba5e46b-efb1-458f-950c-972114d30d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    xprev = x[1,:t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "640bd1bc-90a2-4b93-afec-9b8c5b197455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9006, -1.8652],\n",
       "        [-0.5501, -0.6626],\n",
       "        [ 0.7592,  0.1089],\n",
       "        [ 2.0645, -1.2541],\n",
       "        [ 0.3956,  0.4751],\n",
       "        [-0.0936, -0.5730],\n",
       "        [-0.9944,  1.8074],\n",
       "        [ 0.2255,  0.1344]])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "398896d9-4b9a-4d17-b302-f85b033585cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9006, -1.8652],\n",
       "        [-0.5501, -0.6626],\n",
       "        [ 0.7592,  0.1089],\n",
       "        [ 2.0645, -1.2541],\n",
       "        [ 0.3956,  0.4751],\n",
       "        [-0.0936, -0.5730],\n",
       "        [-0.9944,  1.8074],\n",
       "        [ 0.2255,  0.1344]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xprev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "02e3fb21-e6ef-4cb3-a614-e6c83b5dd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.randn(B,T,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "0254542e-0877-46fa-adb4-66b1db01ad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9006, -1.8652],\n",
       "        [ 0.1752, -1.2639],\n",
       "        [ 0.3699, -0.8063],\n",
       "        [ 0.7935, -0.9183],\n",
       "        [ 0.7139, -0.6396],\n",
       "        [ 0.5793, -0.6285],\n",
       "        [ 0.3545, -0.2805],\n",
       "        [ 0.3384, -0.2286]])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "2ba9047a-0ea1-4b5b-b9d5-842f81043a91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in range(T):\n",
    "    xprev = x[1,:t+1]\n",
    "    xbow[1,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5cf5e04a-3655-4f19-aca9-8df5c9d93bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9006, -1.8652],\n",
       "        [ 0.1752, -1.2639],\n",
       "        [ 0.3699, -0.8063],\n",
       "        [ 0.7935, -0.9183],\n",
       "        [ 0.7139, -0.6396],\n",
       "        [ 0.5793, -0.6285],\n",
       "        [ 0.3545, -0.2805],\n",
       "        [ 0.3384, -0.2286]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "c7101707-6a68-4b03-82e3-89622d60504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow = torch.randn(B,T,C) #bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5a6c138c-e9dd-415e-bc0d-9b1f5f5ff575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7547, -0.2010],\n",
       "        [-0.3782,  1.0409],\n",
       "        [-1.8695,  1.4091],\n",
       "        [ 0.5646, -0.6764],\n",
       "        [ 0.5017,  0.3483],\n",
       "        [ 0.2702, -1.6603],\n",
       "        [ 1.0728,  0.6532],\n",
       "        [-0.3484, -0.2632]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "5de9b2f6-644f-400f-8f63-ad8aa6d0c227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7547, -0.2010],\n",
       "        [-0.5665,  0.4199],\n",
       "        [-1.0008,  0.7496],\n",
       "        [-0.6095,  0.3931],\n",
       "        [-0.3872,  0.3842],\n",
       "        [-0.2777,  0.0434],\n",
       "        [-0.0847,  0.1305],\n",
       "        [-0.1177,  0.0813]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "980cad4e-b693-4f00-adb8-023f6ff10222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are using for loops and it is computationally expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "e2f7d03d-340d-4b9e-bf86-035e79e2d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use @ dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf94eba-8f4b-48c8-8f8b-f5564df10753",
   "metadata": {},
   "source": [
    "### MAsked Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b264b177-5578-4f28-95ac-3eefbea9ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = (torch.ones(3, 3))\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "89c93bd8-eb82-4308-a4c9-6344eb718777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4181d961-4d2f-4d32-9416-42d1bacf3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "9647337d-0ef7-4748-b3b2-6123ba02e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "e28339aa-e655-4032-a4b0-cb2f90189d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fc624e30-320d-47bc-b121-03d4020dc6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7547, -0.2010],\n",
       "         [-0.3782,  1.0409],\n",
       "         [-1.8695,  1.4091],\n",
       "         [ 0.5646, -0.6764],\n",
       "         [ 0.5017,  0.3483],\n",
       "         [ 0.2702, -1.6603],\n",
       "         [ 1.0728,  0.6532],\n",
       "         [-0.3484, -0.2632]],\n",
       "\n",
       "        [[ 0.9006, -1.8652],\n",
       "         [-0.5501, -0.6626],\n",
       "         [ 0.7592,  0.1089],\n",
       "         [ 2.0645, -1.2541],\n",
       "         [ 0.3956,  0.4751],\n",
       "         [-0.0936, -0.5730],\n",
       "         [-0.9944,  1.8074],\n",
       "         [ 0.2255,  0.1344]],\n",
       "\n",
       "        [[-0.2598, -0.3317],\n",
       "         [ 0.2633, -0.4496],\n",
       "         [-1.4718, -0.9949],\n",
       "         [-1.7038, -0.7425],\n",
       "         [ 1.1787, -0.0136],\n",
       "         [ 0.0084, -1.1063],\n",
       "         [ 0.0781,  0.3678],\n",
       "         [-0.3091, -0.5354]],\n",
       "\n",
       "        [[-0.4665, -1.3891],\n",
       "         [-0.5641, -1.1680],\n",
       "         [ 1.2953, -1.1608],\n",
       "         [-0.6370, -1.0931],\n",
       "         [ 0.5531,  0.2289],\n",
       "         [ 2.4018, -0.1149],\n",
       "         [-0.8258, -0.5164],\n",
       "         [ 0.1412,  1.5448]]])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4c6faa88-9a1f-47d3-b596-1244c318ed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbow2 = wei@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "bbcecca8-23ef-4d71-a6e4-5f831936590b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.5475e-01, -2.0099e-01],\n",
       "         [-5.6649e-01,  4.1993e-01],\n",
       "         [-1.0008e+00,  7.4965e-01],\n",
       "         [-6.0947e-01,  3.9314e-01],\n",
       "         [-3.8724e-01,  3.8416e-01],\n",
       "         [-2.7767e-01,  4.3414e-02],\n",
       "         [-8.4742e-02,  1.3053e-01],\n",
       "         [-1.1770e-01,  8.1312e-02]],\n",
       "\n",
       "        [[ 9.0056e-01, -1.8652e+00],\n",
       "         [ 1.7521e-01, -1.2639e+00],\n",
       "         [ 3.6987e-01, -8.0631e-01],\n",
       "         [ 7.9353e-01, -9.1826e-01],\n",
       "         [ 7.1394e-01, -6.3958e-01],\n",
       "         [ 5.7935e-01, -6.2849e-01],\n",
       "         [ 3.5453e-01, -2.8050e-01],\n",
       "         [ 3.3840e-01, -2.2864e-01]],\n",
       "\n",
       "        [[-2.5981e-01, -3.3167e-01],\n",
       "         [ 1.7636e-03, -3.9064e-01],\n",
       "         [-4.8942e-01, -5.9206e-01],\n",
       "         [-7.9303e-01, -6.2967e-01],\n",
       "         [-3.9868e-01, -5.0645e-01],\n",
       "         [-3.3084e-01, -6.0642e-01],\n",
       "         [-2.7242e-01, -4.6725e-01],\n",
       "         [-2.7700e-01, -4.7577e-01]],\n",
       "\n",
       "        [[-4.6654e-01, -1.3891e+00],\n",
       "         [-5.1532e-01, -1.2786e+00],\n",
       "         [ 8.8220e-02, -1.2393e+00],\n",
       "         [-9.3080e-02, -1.2027e+00],\n",
       "         [ 3.6159e-02, -9.1642e-01],\n",
       "         [ 4.3043e-01, -7.8283e-01],\n",
       "         [ 2.5096e-01, -7.4477e-01],\n",
       "         [ 2.3724e-01, -4.5857e-01]]])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "ccf144df-af29-4507-9e3b-ecb77876be80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.7547, -0.2010],\n",
       "         [-0.5665,  0.4199],\n",
       "         [-1.0008,  0.7496],\n",
       "         [-0.6095,  0.3931],\n",
       "         [-0.3872,  0.3842],\n",
       "         [-0.2777,  0.0434],\n",
       "         [-0.0847,  0.1305],\n",
       "         [-0.1177,  0.0813]]),\n",
       " tensor([[-0.7547, -0.2010],\n",
       "         [-0.5665,  0.4199],\n",
       "         [-1.0008,  0.7496],\n",
       "         [-0.6095,  0.3931],\n",
       "         [-0.3872,  0.3842],\n",
       "         [-0.2777,  0.0434],\n",
       "         [-0.0847,  0.1305],\n",
       "         [-0.1177,  0.0813]]))"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[0] ,xbow[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcdb16-1fe5-48b7-a61e-6e35ee37e1c0",
   "metadata": {},
   "source": [
    "### Xbow is normal averaring and Xbow is using identity and matrix multiplication averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "8e53d01b-c445-4d67-bf97-ca4ca90a3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "91d178e5-40a0-43b8-9d10-9e28cec70755",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "0d47dd11-cbbf-4dff-b2fa-2dd17dee6f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ff92937c-a3f9-49fd-b328-a77936217eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei =(torch.zeros(T, T))\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9aa9657f-6abb-4cf4-9495-13326414d80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.masked_fill(tril == 0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "87f53617-cedd-4b15-98dd-419c062e3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei =  wei.masked_fill(tril == 0,float('-inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2b634f07-7c5a-4f03-9437-677f8d015be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei = F.softmax(wei,dim=1)\n",
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "6f0d14ce-85ab-47df-917d-6b357cea2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax = exp()/sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "4d35ef02-115d-44fc-bb57-c51af1cb9b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use Softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # past cannot communicate\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "xbow3 = wei @ x\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b3aa85df-503a-4c5e-ad3c-f8fc80c73a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "0c2f0085-d72e-44d0-85a8-4e630093f14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.00001, 2.0, 3.0])\n",
    "b = torch.tensor([1.00001, 2.0, 3.0])\n",
    "\n",
    "torch.allclose(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "8e691338-e47f-4c36-9b9e-379ec584f67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb_table): Embedding(65, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd =32\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocabsize, n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd , vocabsize)\n",
    "        \n",
    "    def forward(self, ip , targets=None ):\n",
    "        token_emb = self.token_emb_table(ip)\n",
    "        logits = self.lm_head(token_emb)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(ip)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a700a3bf-142b-453d-82bd-9e34093d7605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb_table): Embedding(65, 32)\n",
       "  (position_emb_table): Embedding(8, 32)\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd =32\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocabsize, n_embd)\n",
    "        self.position_emb_table = nn.Embedding(block_size, n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd , vocabsize)\n",
    "        \n",
    "    def forward(self, ip , targets=None ):\n",
    "        B, t = ip.shape\n",
    "        \n",
    "        token_emb = self.token_emb_table(ip)\n",
    "        pos_emb = self.position_emb_table(torch.arange(T, device = device)) # (T,C)\n",
    "        x = token_emb + pos_emb\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(ip)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97113fb-8828-49b5-b87f-603d572f04d9",
   "metadata": {},
   "source": [
    "### Self Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "e3d34d4e-817b-4016-9c78-6309c99f55d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32\n",
    "x=torch.randn(B,T,C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f86f1e84-3659-4fce-8f9b-dc7eda51233c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700, -0.3596,  ..., -0.8016,  1.5236,  2.5086],\n",
       "         [-0.6631, -0.2513,  1.0101,  ...,  1.5333,  1.6097, -0.4032],\n",
       "         [-0.8345,  0.5978, -0.0514,  ..., -0.4370, -1.0012, -0.4094],\n",
       "         ...,\n",
       "         [-0.8961,  0.0662, -0.0563,  ...,  2.1382,  0.5114,  1.2191],\n",
       "         [ 0.1910, -0.3425,  1.7955,  ...,  0.3699, -0.5556, -0.3983],\n",
       "         [-0.5819, -0.2208,  0.0135,  ..., -1.9079, -0.5276,  1.0807]],\n",
       "\n",
       "        [[ 0.4562, -1.0917, -0.8207,  ...,  0.0512, -0.6576, -2.5729],\n",
       "         [ 0.0210,  1.0060, -1.2492,  ...,  0.7859, -1.1501,  1.3132],\n",
       "         [ 2.2007, -0.2195,  0.5427,  ..., -0.6445,  1.0834, -0.7995],\n",
       "         ...,\n",
       "         [ 0.3091,  1.1661, -2.1821,  ...,  0.6151,  0.6763,  0.6228],\n",
       "         [ 0.0943, -0.3156,  0.7850,  ..., -1.5735,  1.3876,  0.7251],\n",
       "         [ 0.6455, -0.3313, -1.0390,  ...,  0.0895, -0.3748, -0.4781]],\n",
       "\n",
       "        [[-0.6067,  1.8328,  0.2931,  ...,  1.0041,  0.8656,  0.1688],\n",
       "         [-0.2352, -0.2586,  0.0131,  ...,  0.6690,  0.7535, -0.5359],\n",
       "         [-1.0277,  0.5347, -0.7958,  ...,  1.0711,  0.4901, -0.4876],\n",
       "         ...,\n",
       "         [-0.6896, -0.7080, -0.3152,  ..., -2.0662, -1.1418, -0.1391],\n",
       "         [ 1.0827,  1.1522,  0.5198,  ...,  0.4970,  0.0585,  0.1033],\n",
       "         [ 0.0720,  1.1080,  0.7293,  ...,  0.3967, -0.9755,  0.5122]],\n",
       "\n",
       "        [[ 0.3330,  1.0995,  0.4034,  ...,  1.6634, -0.4718,  0.5857],\n",
       "         [-0.9579,  0.9435, -2.1992,  ..., -0.7296,  0.1653, -0.3390],\n",
       "         [ 1.5416,  1.0231,  1.3392,  ..., -0.0433, -0.2505, -0.7493],\n",
       "         ...,\n",
       "         [ 0.7450,  0.7170,  1.2668,  ...,  1.9359,  2.0350,  2.0187],\n",
       "         [ 0.0323, -0.6337,  0.2938,  ..., -0.3297, -0.0192,  0.9225],\n",
       "         [ 0.9187,  0.2998,  0.6106,  ...,  0.8282, -0.4826,  1.8330]]])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "85e48d57-8f26-4cf6-a5ae-a7146312511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias =False) # C =32 >> head_size=16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B,T,16)\n",
    "q= query(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ca765e09-85d6-4d6e-92d4-44a58b6601a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "0720b891-c568-4110-856a-f4c704c4b767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "c2266a4b-f305-49e7-8828-07521286249e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 8])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-2,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "6075b511-68af-4748-80d4-98a90d4ac320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "3143e66d-3d54-40af-a225-bca8c50d5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei = q @ k.transpose(-2,-1)  #(B,T 16) @ (B, 16, T) --> (B,T,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c94d3533-7f28-4113-8d89-9dfc6dc2f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # past cannot communicate\n",
    "wei = F.softmax(wei, dim=-1) #normalize\n",
    "out = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "0dd09e62-c32f-409d-beb7-04913337063b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "1fd434ee-d0cd-4ff5-aaa8-4fc858df3e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3351, 0.6649, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2877, 0.2753, 0.4370, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3407, 0.2150, 0.2306, 0.2138, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1604, 0.1730, 0.1632, 0.1601, 0.3434, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1387, 0.1784, 0.1393, 0.1375, 0.2694, 0.1366, 0.0000, 0.0000],\n",
       "        [0.1455, 0.1845, 0.1284, 0.1281, 0.1364, 0.1502, 0.1270, 0.0000],\n",
       "        [0.1122, 0.1195, 0.1161, 0.1382, 0.1164, 0.1179, 0.1400, 0.1396]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "b3f3fb9b-e794-4132-b469-25f1d448c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the 8th token 0.1400 this one seems interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "47826d16-11f5-471d-b9e1-d0d2abfabafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias =False) # C =32 >> head_size=16\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x) # (B,T,16)\n",
    "q= query(x)\n",
    "v= value(x)\n",
    "\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # past cannot communicate\n",
    "wei = F.softmax(wei, dim=-1) #normalize\n",
    "out = wei @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "132d6453-bbe3-46e3-a2a3-71b5b17c3683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "5b0ef839-31bd-463a-b214-747f91798a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # only encoder u delete this\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c10dd90e-3daa-444d-961d-4f28db9712b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1808, -0.0700, -0.3596,  ..., -0.8016,  1.5236,  2.5086],\n",
       "         [-0.6631, -0.2513,  1.0101,  ...,  1.5333,  1.6097, -0.4032],\n",
       "         [-0.8345,  0.5978, -0.0514,  ..., -0.4370, -1.0012, -0.4094],\n",
       "         ...,\n",
       "         [-0.8961,  0.0662, -0.0563,  ...,  2.1382,  0.5114,  1.2191],\n",
       "         [ 0.1910, -0.3425,  1.7955,  ...,  0.3699, -0.5556, -0.3983],\n",
       "         [-0.5819, -0.2208,  0.0135,  ..., -1.9079, -0.5276,  1.0807]],\n",
       "\n",
       "        [[ 0.4562, -1.0917, -0.8207,  ...,  0.0512, -0.6576, -2.5729],\n",
       "         [ 0.0210,  1.0060, -1.2492,  ...,  0.7859, -1.1501,  1.3132],\n",
       "         [ 2.2007, -0.2195,  0.5427,  ..., -0.6445,  1.0834, -0.7995],\n",
       "         ...,\n",
       "         [ 0.3091,  1.1661, -2.1821,  ...,  0.6151,  0.6763,  0.6228],\n",
       "         [ 0.0943, -0.3156,  0.7850,  ..., -1.5735,  1.3876,  0.7251],\n",
       "         [ 0.6455, -0.3313, -1.0390,  ...,  0.0895, -0.3748, -0.4781]],\n",
       "\n",
       "        [[-0.6067,  1.8328,  0.2931,  ...,  1.0041,  0.8656,  0.1688],\n",
       "         [-0.2352, -0.2586,  0.0131,  ...,  0.6690,  0.7535, -0.5359],\n",
       "         [-1.0277,  0.5347, -0.7958,  ...,  1.0711,  0.4901, -0.4876],\n",
       "         ...,\n",
       "         [-0.6896, -0.7080, -0.3152,  ..., -2.0662, -1.1418, -0.1391],\n",
       "         [ 1.0827,  1.1522,  0.5198,  ...,  0.4970,  0.0585,  0.1033],\n",
       "         [ 0.0720,  1.1080,  0.7293,  ...,  0.3967, -0.9755,  0.5122]],\n",
       "\n",
       "        [[ 0.3330,  1.0995,  0.4034,  ...,  1.6634, -0.4718,  0.5857],\n",
       "         [-0.9579,  0.9435, -2.1992,  ..., -0.7296,  0.1653, -0.3390],\n",
       "         [ 1.5416,  1.0231,  1.3392,  ..., -0.0433, -0.2505, -0.7493],\n",
       "         ...,\n",
       "         [ 0.7450,  0.7170,  1.2668,  ...,  1.9359,  2.0350,  2.0187],\n",
       "         [ 0.0323, -0.6337,  0.2938,  ..., -0.3297, -0.0192,  0.9225],\n",
       "         [ 0.9187,  0.2998,  0.6106,  ...,  0.8282, -0.4826,  1.8330]]])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5c40132e-5383-4f4d-80c4-511badb6b72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f4a7d7-158e-4a48-9d3b-ac66cabbf894",
   "metadata": {},
   "source": [
    "### so here all these 4 are independent and each with communicate to them selves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecf916-f1fc-4442-a204-ac4c1bb8e93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled attendion = if u "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4083f6-5732-4dd8-ae66-93b403e4258e",
   "metadata": {},
   "source": [
    "### divide by sqrt(dmodel) -just to normalize or scale to control the varience at inintialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "0dd0d158-dd68-49ad-b6de-34409fc10b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "47aaf57b-3d42-4548-b592-6db7ed7a0b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3164, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "ffaf086f-28c4-4f2e-98ea-69345fa9eadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9224, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "56b2000a-b3c6-48c7-9d98-3498ecd82391",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "71e4a2e9-aa76-4401-a5fe-0957e539dabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1201, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a9524-7688-4dce-9b4b-bfc4b69132d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 4: self-attention!\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) # only encoder u delete this\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "#out = wei @ x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e46341-9522-46f7-a3a8-03e3e62516ce",
   "metadata": {},
   "source": [
    "#### Self Attention Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "ad0954d8-b5cc-4c40-943b-70d8fa4540ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(C, head_size, bias =False) # C =32 >> head_size=16\n",
    "        self.query = nn.Linear(C, head_size, bias=False)\n",
    "        self.value = nn.Linear(C, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self,x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B, T, 16)\n",
    "        q = self.query(x)\n",
    "        wei =  q @ k.transpose(-2, -1) * C**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "74af297f-5e21-47c7-8966-a911fc290cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb_table): Embedding(65, 32)\n",
       "  (position_emb_table): Embedding(8, 32)\n",
       "  (selfA_head): Head(\n",
       "    (key): Linear(in_features=32, out_features=32, bias=False)\n",
       "    (query): Linear(in_features=32, out_features=32, bias=False)\n",
       "    (value): Linear(in_features=32, out_features=32, bias=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd =32\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocabsize, n_embd)\n",
    "        self.position_emb_table = nn.Embedding(block_size, n_embd)\n",
    "        self.selfA_head = Head(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd , vocabsize)\n",
    "        \n",
    "        \n",
    "    def forward(self, ip , targets=None ):\n",
    "        B, t = ip.shape\n",
    "        \n",
    "        token_emb = self.token_emb_table(ip)\n",
    "        pos_emb = self.position_emb_table(torch.arange(T, device = device)) # (T,C)\n",
    "        x = token_emb + pos_emb\n",
    "        x = selfA_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            ip_cond = ip[:,-block_size:] # crop input to block size  ## as positional embeddings\n",
    "            logits,loss = self(ip_cond)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b3ced7-443c-4fa0-bbe5-1bae734f6b39",
   "metadata": {},
   "source": [
    "## Multi Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "70576788-9c56-4242-9248-f2bd0349cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(nn.Module):\n",
    "    def __init__(self,num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "    def forward(self, x):\n",
    "        return torch.cat([h(x) for h in self.heads], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "e55c200d-7ec3-402b-b0ee-0fe4c6acfb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb_table): Embedding(65, 32)\n",
       "  (position_emb_table): Embedding(8, 32)\n",
       "  (selfA_head): MultiAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x Head(\n",
       "        (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "        (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "        (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd =32\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocabsize, n_embd)\n",
    "        self.position_emb_table = nn.Embedding(block_size, n_embd)\n",
    "        self.selfA_head = MultiAttention(4, n_embd//4)\n",
    "        self.lm_head = nn.Linear(n_embd , vocabsize)\n",
    "        \n",
    "        \n",
    "    def forward(self, ip , targets=None ):\n",
    "        B, T = ip.shape\n",
    "        \n",
    "        token_emb = self.token_emb_table(ip)\n",
    "        pos_emb = self.position_emb_table(torch.arange(T, device = device)) # (T,C)\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.selfA_head(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            ip_cond = ip[:,-block_size:] # crop input to block size  ## as positional embeddings\n",
    "            logits,loss = self(ip_cond)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "a9677b13-3a85-4860-9126-e47972ced84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1822, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for steps in range(10000):\n",
    "    xb,yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none = True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354664c9-8103-4ed9-a771-29f749607523",
   "metadata": {},
   "source": [
    "### Feed Forward layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "f1dafd3e-e2a6-4129-a767-3deaf573e0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#once we multiply the and get attention layer we send to FFL so that they will understand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "bb25f48f-21aa-4c5e-a3eb-f183f496e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed forward is individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "6a6f96c4-e58a-4b2d-96f1-6bb76d5b6c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, n_embd),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "158207ac-6828-4391-aa04-db98616e4149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bigram(\n",
       "  (token_emb_table): Embedding(65, 32)\n",
       "  (position_emb_table): Embedding(8, 32)\n",
       "  (selfA_head): MultiAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-3): 4 x Head(\n",
       "        (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "        (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "        (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=32, out_features=65, bias=True)\n",
       "  (ffwd): FeedForward(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd =32\n",
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocabsize):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocabsize, n_embd)\n",
    "        self.position_emb_table = nn.Embedding(block_size, n_embd)\n",
    "        self.selfA_head = MultiAttention(4, n_embd//4)\n",
    "        self.lm_head = nn.Linear(n_embd , vocabsize)\n",
    "        self.ffwd = FeedForward(n_embd)\n",
    "        \n",
    "    def forward(self, ip , targets=None ):\n",
    "        B, T = ip.shape\n",
    "        \n",
    "        token_emb = self.token_emb_table(ip)\n",
    "        pos_emb = self.position_emb_table(torch.arange(T, device = device)) # (T,C)\n",
    "        x = token_emb + pos_emb\n",
    "        x = self.selfA_head(x)\n",
    "        x = self.ffwd(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T ,C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "    \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        # prob = logits > exp(logits)/exp(logits).sum()==probs > prob[y].log()/mean  \n",
    "\n",
    "        return logits , loss\n",
    "    def generate(self, ip, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            ip_cond = ip[:,-block_size:] # crop input to block size  ## as positional embeddings\n",
    "            logits,loss = self(ip_cond)\n",
    "            logits = logits[:,-1,:] # B,C\n",
    "            probs = F.softmax(logits,dim=1)\n",
    "            ip_next = torch.multinomial(probs,num_samples=1)\n",
    "            ip = torch.cat((ip,ip_next),dim=1)\n",
    "        return ip\n",
    "\n",
    "m = Bigram(vocabsize)\n",
    "m.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "315f1bbe-7c4c-45dd-a60b-6ea6df6412b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1919879560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[506], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    FINE TUNE > RL\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "FINE TUNE > RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8364bba1-2915-49d1-9fc2-80c3b84bbec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147656d0-8348-49bc-af22-741852cbe230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
